{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "40 MultiLabel MultiClass Classification in 10 Minutes with BERT-TensorFlow-Sigmoid-LocalModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMro31UDzYGKemKuWOMHfaj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dirkster99/PyNotes/blob/master/Transformers/40_MultiLabel_MultiClass_Classification_in_10_Minutes_with_BERT_TensorFlow_Sigmoid_LocalModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0lTwJkEZzlE"
      },
      "source": [
        "# Multilabel MultiClass Classification in 10 Minutes with BERT-TensorFlow and SoftMax\r\n",
        "- Based on Article  \r\n",
        "  https://towardsdatascience.com/sentiment-analysis-in-10-minutes-with-bert-and-hugging-face-294e8a04b671"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaywxYQ7Owcs"
      },
      "source": [
        "- Data Source: TBD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07aNXeymDgN6"
      },
      "source": [
        "## Install Transformers Python Library to run it in CoLab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpyyhRtWZxzD",
        "outputId": "5d3d5665-0cf2-486c-e5a1-4b19bd346297"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/54/5ca07ec9569d2f232f3166de5457b63943882f7950ddfcc887732fc7fb23/transformers-4.3.3-py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 32.1MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 37.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=08ae72127e115837309fb425317f3d44439e37b34dc67a9a4d3c6f55d60aad3e\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUM0j_YvocQM"
      },
      "source": [
        "## Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BjAsT3VI-ma",
        "outputId": "5dbb9e2b-abb4-4f76-f1de-edb9ed17a574"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/gdrive') #, force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m41zeSgqs30u",
        "outputId": "db62b372-8b2f-4603-8ee1-94d3cdb7e1e9"
      },
      "source": [
        "myModelPath = '/gdrive/MyDrive/Colab Notebooks/Transformers/LocalModelUsage/bert-base-uncased/'\r\n",
        "myDataPath = '/gdrive/MyDrive/Colab Notebooks/MultiLabelText/ToxicComments/data/'\r\n",
        "!ls {myModelPath.replace(' ', '\\ ')} -lh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 1.5G\n",
            "-rw------- 1 root root  433 Feb 23 18:20 config.json\n",
            "-rw------- 1 root root 421M Feb 23 18:20 pytorch_model.bin\n",
            "-rw------- 1 root root 8.8K Feb 23 18:20 README.md\n",
            "-rw------- 1 root root 510M Feb 23 18:20 rust_model.ot\n",
            "-rw------- 1 root root 512M Feb 23 18:20 tf_model.h5\n",
            "-rw------- 1 root root   28 Feb 23 18:20 tokenizer_config.json\n",
            "-rw------- 1 root root 456K Feb 23 18:20 tokenizer.json\n",
            "-rw------- 1 root root 227K Feb 23 18:20 vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_JCnejtyRSy"
      },
      "source": [
        "# Dataset\r\n",
        "Here, we use Toxic Comment Classification Challenge dataset from Kaggle. It provided  Wikipedia comments which have been labeled by human raters for toxic behavior. The types of toxicity are:\r\n",
        "\r\n",
        "- toxic\r\n",
        "- severe_toxic\r\n",
        "- obscene\r\n",
        "- threat\r\n",
        "- insult\r\n",
        "- Identity_hate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba7RIrJBuTgh"
      },
      "source": [
        "## Prepare Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6hSxmfntHwa"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "import os\r\n",
        "\r\n",
        "TRAIN_DATA = myDataPath + 'train.csv'\r\n",
        "df = pd.read_csv(TRAIN_DATA)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5L0AFzP0oz_4",
        "outputId": "a7f1d572-ddd3-4104-d89e-f655dd185851"
      },
      "source": [
        "textLabels = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... identity_hate\n",
              "0  0000997932d777bf  ...             0\n",
              "1  000103f0d9cfb60f  ...             0\n",
              "2  000113f07ec002fd  ...             0\n",
              "3  0001b41b1c6bb37e  ...             0\n",
              "4  0001d958c54c6e35  ...             0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "AuyIKSk2jrRP",
        "outputId": "2460347a-6463-49be-e6d0-be1cbaa7a73c"
      },
      "source": [
        "# convert all label columns into 1 label column containing a list of values\r\n",
        "df['LABEL_COLUMN'] = (df[textLabels].to_numpy().tolist())\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>LABEL_COLUMN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ...        LABEL_COLUMN\n",
              "0  0000997932d777bf  ...  [0, 0, 0, 0, 0, 0]\n",
              "1  000103f0d9cfb60f  ...  [0, 0, 0, 0, 0, 0]\n",
              "2  000113f07ec002fd  ...  [0, 0, 0, 0, 0, 0]\n",
              "3  0001b41b1c6bb37e  ...  [0, 0, 0, 0, 0, 0]\n",
              "4  0001d958c54c6e35  ...  [0, 0, 0, 0, 0, 0]\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Ps-94E6OpBam",
        "outputId": "380a5585-3579-4734-ee3c-093c702237c6"
      },
      "source": [
        "# select label and value columns\r\n",
        "df = df[['LABEL_COLUMN', 'comment_text']]\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LABEL_COLUMN</th>\n",
              "      <th>comment_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         LABEL_COLUMN                                       comment_text\n",
              "0  [0, 0, 0, 0, 0, 0]  Explanation\\nWhy the edits made under my usern...\n",
              "1  [0, 0, 0, 0, 0, 0]  D'aww! He matches this background colour I'm s...\n",
              "2  [0, 0, 0, 0, 0, 0]  Hey man, I'm really not trying to edit war. It...\n",
              "3  [0, 0, 0, 0, 0, 0]  \"\\nMore\\nI can't make any real suggestions on ...\n",
              "4  [0, 0, 0, 0, 0, 0]  You, sir, are my hero. Any chance you remember..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPMWfVT-pBXC"
      },
      "source": [
        "# rename column\r\n",
        "df.rename(columns = {'comment_text' : 'DATA_COLUMN'}, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "r1C7Yc3ApBTK",
        "outputId": "07e3c6a4-a030-475b-9def-c36bcb97d567"
      },
      "source": [
        "# print data input at the end of stagging\r\n",
        "print (textLabels)\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LABEL_COLUMN</th>\n",
              "      <th>DATA_COLUMN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         LABEL_COLUMN                                        DATA_COLUMN\n",
              "0  [0, 0, 0, 0, 0, 0]  Explanation\\nWhy the edits made under my usern...\n",
              "1  [0, 0, 0, 0, 0, 0]  D'aww! He matches this background colour I'm s...\n",
              "2  [0, 0, 0, 0, 0, 0]  Hey man, I'm really not trying to edit war. It...\n",
              "3  [0, 0, 0, 0, 0, 0]  \"\\nMore\\nI can't make any real suggestions on ...\n",
              "4  [0, 0, 0, 0, 0, 0]  You, sir, are my hero. Any chance you remember..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-KRMQGfc-bE",
        "outputId": "bead729f-8730-4055-ae0b-a3518e06ef7a"
      },
      "source": [
        "splitSize = df.count() * .8\r\n",
        "splitSize"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LABEL_COLUMN    127656.8\n",
              "DATA_COLUMN     127656.8\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5w5qeWTLc-XG"
      },
      "source": [
        "#people_copy = people.copy()\r\n",
        "train = df.sample(frac=0.75, random_state=0)\r\n",
        "test = df.drop(train.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3wtIxKBc-NR",
        "outputId": "03c44343-ab4a-40ee-8abe-651f1655dbdd"
      },
      "source": [
        "print (f\"{test.count()} \\n\\n{train.count()}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LABEL_COLUMN    39893\n",
            "DATA_COLUMN     39893\n",
            "dtype: int64 \n",
            "\n",
            "LABEL_COLUMN    119678\n",
            "DATA_COLUMN     119678\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxCCr99vgJBx",
        "outputId": "9828af1d-77f3-49ff-97cc-36cb76b904aa"
      },
      "source": [
        "print (f'Number of Labels: {len(textLabels)},\\nLabels:{textLabels}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Labels: 6,\n",
            "Labels:['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrXQ6Tw1fuBF"
      },
      "source": [
        "## Load the Model\r\n",
        "See Load and Save notebooks in this repository to understand how Transformers models cen be:\r\n",
        "1. Downloaded\r\n",
        "2. Stored Locally and\r\n",
        "3. be used from Local Storage.\r\n",
        "\r\n",
        "This should be interesting if you work in a cloud environment without Internet connection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPqJYYaTEeA2"
      },
      "source": [
        "Here we tell the model that we whish to train on **20 label values** instead of the original 1 label (with 1 or 0 values) for which the original model was designed. This is why the test below tells us that we better should train this model. So, training it we will :-)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKyCtNxmaBNL",
        "outputId": "c7aeda64-8fe5-48b1-84e3-09bd4a89b064"
      },
      "source": [
        "from transformers import BertTokenizer, TFBertForSequenceClassification\r\n",
        "from transformers import InputExample, InputFeatures\r\n",
        "\r\n",
        "model = TFBertForSequenceClassification.from_pretrained(myModelPath, num_labels=len(textLabels))\r\n",
        "tokenizer = BertTokenizer.from_pretrained(myModelPath)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at /gdrive/MyDrive/Colab Notebooks/Transformers/LocalModelUsage/bert-base-uncased/ and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omoxwyaEaH5R",
        "outputId": "d35e6b69-cbdd-4607-c2be-d1cf4a3456ab"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"tf_bert_for_sequence_classification\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bert (TFBertMainLayer)       multiple                  109482240 \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "classifier (Dense)           multiple                  4614      \n",
            "=================================================================\n",
            "Total params: 109,486,854\n",
            "Trainable params: 109,486,854\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OY__mmNzbFPs"
      },
      "source": [
        "## Creating Input Sequences\r\n",
        "We have two pandas Dataframe objects waiting for us to convert them into suitable objects for the BERT model. We will take advantage of the InputExample function that helps us to create sequences from our dataset. The InputExample function can be called as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgcKjdFIbCAL",
        "outputId": "4d50b555-10dd-44b1-ce26-efc3f3e2e3d4"
      },
      "source": [
        "# transformers.InputExample\r\n",
        "InputExample(guid=None,\r\n",
        "             text_a = \"Hello, world\",\r\n",
        "             text_b = None,\r\n",
        "             label = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "InputExample(guid=None, text_a='Hello, world', text_b=None, label=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbU6diuYbNVM"
      },
      "source": [
        "Now we will create two main functions:\r\n",
        "\r\n",
        "1 — `convert_data_to_examples`: This will accept our train and test datasets and convert each row into an InputExample object.\r\n",
        "\r\n",
        "2 — `convert_examples_to_tf_dataset`: This function will tokenize the InputExample objects, then create the required input format with the tokenized objects, finally, create an input dataset that we can feed to the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZobDj7ZibI78"
      },
      "source": [
        "def convert_data_to_examples(train, test, DATA_COLUMN, LABEL_COLUMN): \r\n",
        "  train_InputExamples = train.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\r\n",
        "                                                          text_a = x[DATA_COLUMN], \r\n",
        "                                                          text_b = None,\r\n",
        "                                                          label = x[LABEL_COLUMN]), axis = 1)\r\n",
        "\r\n",
        "  validation_InputExamples = test.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\r\n",
        "                                                          text_a = x[DATA_COLUMN], \r\n",
        "                                                          text_b = None,\r\n",
        "                                                          label = x[LABEL_COLUMN]), axis = 1)\r\n",
        "  \r\n",
        "  return train_InputExamples, validation_InputExamples  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wUBIWuEbleM"
      },
      "source": [
        "train_InputExamples, validation_InputExamples = convert_data_to_examples(train, \r\n",
        "                                                                           test, \r\n",
        "                                                                           'DATA_COLUMN', \r\n",
        "                                                                           'LABEL_COLUMN')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k52dErBYbVst"
      },
      "source": [
        "def convert_examples_to_tf_dataset(examples, tokenizer, max_length=128):\r\n",
        "    features = [] # -> will hold InputFeatures to be converted later\r\n",
        "\r\n",
        "    for e in examples:\r\n",
        "        # Documentation is really strong for this method, so please take a look at it\r\n",
        "        input_dict = tokenizer.encode_plus(\r\n",
        "            e.text_a,\r\n",
        "            add_special_tokens=True,\r\n",
        "            max_length=max_length, # truncates if len(s) > max_length\r\n",
        "            return_token_type_ids=True,\r\n",
        "            return_attention_mask=True,\r\n",
        "            pad_to_max_length=True, # pads to the right by default # CHECK THIS for pad_to_max_length\r\n",
        "            truncation=True\r\n",
        "        )\r\n",
        "\r\n",
        "        input_ids, token_type_ids, attention_mask = (input_dict[\"input_ids\"],\r\n",
        "            input_dict[\"token_type_ids\"], input_dict['attention_mask'])\r\n",
        "\r\n",
        "        features.append(\r\n",
        "            InputFeatures(\r\n",
        "                input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, label=e.label\r\n",
        "            )\r\n",
        "        )\r\n",
        "\r\n",
        "    def gen():\r\n",
        "        for f in features:\r\n",
        "            yield (\r\n",
        "                {\r\n",
        "                    \"input_ids\": f.input_ids,\r\n",
        "                    \"attention_mask\": f.attention_mask,\r\n",
        "                    \"token_type_ids\": f.token_type_ids,\r\n",
        "                },\r\n",
        "                f.label,\r\n",
        "            )\r\n",
        "\r\n",
        "    return tf.data.Dataset.from_generator(\r\n",
        "        gen,\r\n",
        "        ({\"input_ids\": tf.int32, \"attention_mask\": tf.int32, \"token_type_ids\": tf.int32}, tf.int64),\r\n",
        "        (\r\n",
        "            {\r\n",
        "                \"input_ids\": tf.TensorShape([None]),\r\n",
        "                \"attention_mask\": tf.TensorShape([None]),\r\n",
        "                \"token_type_ids\": tf.TensorShape([None]),\r\n",
        "            },\r\n",
        "            tf.TensorShape([]),\r\n",
        "        ),\r\n",
        "    )\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n44iQfkQba9M"
      },
      "source": [
        "DATA_COLUMN = 'DATA_COLUMN'\r\n",
        "LABEL_COLUMN = 'LABEL_COLUMN'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsahLWQIfsMv",
        "outputId": "06ed5552-2b19-424c-d8b8-c9633d9112c8"
      },
      "source": [
        "print (str(type(DATA_COLUMN)) + ' ' + DATA_COLUMN)\r\n",
        "print (str(type(LABEL_COLUMN)) + ' ' + LABEL_COLUMN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'str'> DATA_COLUMN\n",
            "<class 'str'> LABEL_COLUMN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "GzSyFUoKgbNE",
        "outputId": "d4440335-ea87-485e-abe5-d62c8521f74d"
      },
      "source": [
        "train.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LABEL_COLUMN</th>\n",
              "      <th>DATA_COLUMN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>74251</th>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>\"\\nI haven't paraphrased you at all, Gary.  Yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131406</th>\n",
              "      <td>[1, 0, 0, 0, 0, 0]</td>\n",
              "      <td>I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120969</th>\n",
              "      <td>[0, 0, 0, 0, 1, 0]</td>\n",
              "      <td>I'm sorry. I'd like to unreservedly retract my...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121827</th>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>I don't know if this is exactly like the Press...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4771</th>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>Thank you all, we'll all improve the Wikipedia...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              LABEL_COLUMN                                        DATA_COLUMN\n",
              "74251   [0, 0, 0, 0, 0, 0]  \"\\nI haven't paraphrased you at all, Gary.  Yo...\n",
              "131406  [1, 0, 0, 0, 0, 0]  I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED ...\n",
              "120969  [0, 0, 0, 0, 1, 0]  I'm sorry. I'd like to unreservedly retract my...\n",
              "121827  [0, 0, 0, 0, 0, 0]  I don't know if this is exactly like the Press...\n",
              "4771    [0, 0, 0, 0, 0, 0]  Thank you all, we'll all improve the Wikipedia..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BR_puwpBbtid",
        "outputId": "d780b354-ed0e-4bab-bf99-79cc46de6812"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "train_InputExamples, validation_InputExamples = convert_data_to_examples(train, test, DATA_COLUMN, LABEL_COLUMN)\r\n",
        "\r\n",
        "train_data = convert_examples_to_tf_dataset(list(train_InputExamples), tokenizer)\r\n",
        "train_data = train_data.shuffle(100).batch(32).repeat(2)\r\n",
        "\r\n",
        "validation_data = convert_examples_to_tf_dataset(list(validation_InputExamples), tokenizer)\r\n",
        "validation_data = validation_data.batch(32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2155: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5min 5s, sys: 504 ms, total: 5min 5s\n",
            "Wall time: 5min 5s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qe-9PgI_ckZv"
      },
      "source": [
        "## Configuring the BERT model and Fine-tuning\r\n",
        "We will use Adam as our optimizer, CategoricalCrossentropy as our loss function, and SparseCategoricalAccuracy as our accuracy metric. Fine-tuning the model for 2 epochs will give us around 93% accuracy, which is great."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxypaKh8cg3m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6d027188-e8e0-4fc1-bace-5cebaeade27c"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0), \r\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \r\n",
        "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])\r\n",
        "\r\n",
        "model.fit(train_data, epochs=2, validation_data=validation_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fad1bc2ce50>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fad1bc2ce50>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7fad37059c20> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function wrap at 0x7fad37059c20> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-6536548c41a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0), \\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \\n              metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])\\n\\nmodel.fit(train_data, epochs=2, validation_data=validation_data)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument:  ValueError: `generator` yielded an element of shape (6,) where an element of shape () was expected.\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 620, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 938, in generator_py_func\n    (ret_array.shape, expected_shape))\n\nValueError: `generator` yielded an element of shape (6,) where an element of shape () was expected.\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n  (1) Invalid argument:  ValueError: `generator` yielded an element of shape (6,) where an element of shape () was expected.\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 620, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 938, in generator_py_func\n    (ret_array.shape, expected_shape))\n\nValueError: `generator` yielded an element of shape (6,) where an element of shape () was expected.\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_2]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_25808]\n\nFunction call stack:\ntrain_function -> train_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pS9SoNm-dD07"
      },
      "source": [
        "Training the model might take a while, so ensure you enabled the GPU acceleration from the Notebook Settings. After our training is completed, we can move onto making sentiment predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2kIo1BtdOai"
      },
      "source": [
        "## Making Predictions\r\n",
        "I created a list of two reviews I created. The first one is a positive review, while the second one is clearly negative."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2HLb5gFcpL-"
      },
      "source": [
        "pred_sentences = ['This season so far, Morgan and Guzman helped to lead the Cubs at top in ERA, even better than THE rotation at Atlanta.',\r\n",
        "                  'This is the tenth of ten parts of the sci.crypt FAQ.',\r\n",
        "                  'I think that domestication will change behavior to a large degree. Domesticated animals exhibit behaviors not found in the wild.',\r\n",
        "                  \"If anybody wants these changes, they're welcome to them, but you'll have to have the source available and be comfortable munging with it a bit.\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rM2YzQrmdXUa"
      },
      "source": [
        "We need to tokenize our reviews with our pre-trained BERT tokenizer. We will then feed these tokenized sequences to our model and run a final softmax layer to get the predictions. We can then use the argmax function to determine whether our sentiment prediction for the review is positive or negative. Finally, we will print out the results with a simple for loop. The following lines do all of these said operations:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GjvCJ92666f",
        "outputId": "2646c4a2-32b7-493c-b563-04a9abc0f86c"
      },
      "source": [
        "tf_batch = tokenizer(pred_sentences, max_length=128, padding=True, truncation=True, return_tensors='tf')\r\n",
        "tf_outputs = model(tf_batch)\r\n",
        "tf_predictions = tf.nn.softmax(tf_outputs[0], axis=-1)\r\n",
        "tf_predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 20), dtype=float32, numpy=\n",
              "array([[1.9084792e-04, 3.4088054e-04, 2.0756450e-04, 8.6477579e-05,\n",
              "        2.9989792e-04, 2.6212877e-04, 1.9374983e-04, 3.5850867e-04,\n",
              "        1.5933276e-04, 9.9522001e-01, 4.5725811e-04, 8.2916165e-05,\n",
              "        3.6863686e-04, 1.2279976e-04, 2.3117411e-04, 1.3213107e-04,\n",
              "        3.1335116e-04, 4.4700602e-04, 2.9876176e-04, 2.2643096e-04],\n",
              "       [2.1327195e-04, 4.0231278e-04, 1.5158435e-04, 1.2487071e-03,\n",
              "        1.2888614e-03, 1.4331866e-03, 4.6543666e-04, 1.8467591e-04,\n",
              "        4.1545741e-04, 3.4950839e-04, 1.3036636e-03, 9.8752570e-01,\n",
              "        1.5377196e-03, 3.4859296e-04, 4.5611229e-04, 5.4127991e-04,\n",
              "        2.9390829e-04, 9.1435417e-04, 2.4715456e-04, 6.7858823e-04],\n",
              "       [8.5387528e-03, 1.3884273e-03, 3.6678996e-02, 1.5499455e-02,\n",
              "        2.6900356e-03, 4.8267641e-03, 3.8973048e-02, 8.9422697e-03,\n",
              "        6.8014547e-02, 3.9243731e-03, 9.7063286e-03, 7.5493036e-03,\n",
              "        1.5494078e-03, 4.4692346e-01, 3.0200190e-03, 1.8781705e-01,\n",
              "        2.9258033e-02, 8.0084074e-03, 1.6928652e-02, 9.9762589e-02],\n",
              "       [2.1065164e-03, 3.2576597e-01, 8.8707365e-02, 5.6470715e-02,\n",
              "        1.4789161e-02, 4.5041499e-01, 6.5489658e-03, 1.1105003e-03,\n",
              "        1.3902227e-03, 5.3382302e-03, 2.7191723e-03, 1.8104794e-02,\n",
              "        9.9027110e-03, 7.6806580e-04, 8.6228391e-03, 3.2579771e-03,\n",
              "        8.7717123e-04, 9.4070175e-04, 6.7961635e-04, 1.4843607e-03]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "CA1qb0Qt7YII",
        "outputId": "c3233a61-1441-497e-b259-b311946d175c"
      },
      "source": [
        "tf.argmax(tf_predictions, axis=1).numpy()\r\n",
        "index2label[11]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'sci.crypt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxD4gyExdTZ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef8d5fdd-1247-44a7-c4c9-cc75f5880517"
      },
      "source": [
        "tf_batch = tokenizer(pred_sentences, max_length=128, padding=True, truncation=True, return_tensors='tf')\r\n",
        "tf_outputs = model(tf_batch)\r\n",
        "tf_predictions = tf.nn.softmax(tf_outputs[0], axis=-1)\r\n",
        "\r\n",
        "# Get index of predicted label for each sentence\r\n",
        "label = tf.argmax(tf_predictions, axis=1).numpy()\r\n",
        "\r\n",
        "# output human readable label predictions\r\n",
        "for i in range(len(pred_sentences)):\r\n",
        "  print(pred_sentences[i], \": \\n\", index2label[label[i]] +\" with score: \"+ str(tf_predictions[i][label[i]].numpy()))\r\n",
        "  print ()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This season so far, Morgan and Guzman helped to lead the Cubs at top in ERA, even better than THE rotation at Atlanta. : \n",
            " rec.sport.baseball with score: 0.99522\n",
            "\n",
            "This is the tenth of ten parts of the sci.crypt FAQ. : \n",
            " sci.crypt with score: 0.9875257\n",
            "\n",
            "I think that domestication will change behavior to a large degree. Domesticated animals exhibit behaviors not found in the wild. : \n",
            " sci.med with score: 0.44692346\n",
            "\n",
            "If anybody wants these changes, they're welcome to them, but you'll have to have the source available and be comfortable munging with it a bit. : \n",
            " comp.windows.x with score: 0.450415\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUd8tmWUnK28"
      },
      "source": [
        "## Debugging the Final Tensor Shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDRGxQh_V8bt",
        "outputId": "5182dad6-03ad-4915-83d3-d40bbc9d4b3c"
      },
      "source": [
        "tf_predictions.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([4, 20])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRDxUOJmgvK4",
        "outputId": "d3d5c68a-3707-4af3-a049-e4455c4e1c5e"
      },
      "source": [
        "for i in range(len(tf_predictions)):\r\n",
        "  print (tf_predictions[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[1.9084792e-04 3.4088054e-04 2.0756450e-04 8.6477579e-05 2.9989792e-04\n",
            " 2.6212877e-04 1.9374983e-04 3.5850867e-04 1.5933276e-04 9.9522001e-01\n",
            " 4.5725811e-04 8.2916165e-05 3.6863686e-04 1.2279976e-04 2.3117411e-04\n",
            " 1.3213107e-04 3.1335116e-04 4.4700602e-04 2.9876176e-04 2.2643096e-04], shape=(20,), dtype=float32)\n",
            "tf.Tensor(\n",
            "[2.1327195e-04 4.0231278e-04 1.5158435e-04 1.2487071e-03 1.2888614e-03\n",
            " 1.4331866e-03 4.6543666e-04 1.8467591e-04 4.1545741e-04 3.4950839e-04\n",
            " 1.3036636e-03 9.8752570e-01 1.5377196e-03 3.4859296e-04 4.5611229e-04\n",
            " 5.4127991e-04 2.9390829e-04 9.1435417e-04 2.4715456e-04 6.7858823e-04], shape=(20,), dtype=float32)\n",
            "tf.Tensor(\n",
            "[0.00853875 0.00138843 0.036679   0.01549945 0.00269004 0.00482676\n",
            " 0.03897305 0.00894227 0.06801455 0.00392437 0.00970633 0.0075493\n",
            " 0.00154941 0.44692346 0.00302002 0.18781705 0.02925803 0.00800841\n",
            " 0.01692865 0.09976259], shape=(20,), dtype=float32)\n",
            "tf.Tensor(\n",
            "[0.00210652 0.32576597 0.08870737 0.05647071 0.01478916 0.450415\n",
            " 0.00654897 0.0011105  0.00139022 0.00533823 0.00271917 0.01810479\n",
            " 0.00990271 0.00076807 0.00862284 0.00325798 0.00087717 0.0009407\n",
            " 0.00067962 0.00148436], shape=(20,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjcFubhmhFQB",
        "outputId": "b591d960-32ee-406c-9149-2c761a2e01f1"
      },
      "source": [
        "for i in range(len(tf_predictions)):\r\n",
        "  print (str(tf_predictions[i][0]) + ' - ' + str(tf_predictions[i][1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0.00019084792, shape=(), dtype=float32) - tf.Tensor(0.00034088054, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00021327195, shape=(), dtype=float32) - tf.Tensor(0.00040231278, shape=(), dtype=float32)\n",
            "tf.Tensor(0.008538753, shape=(), dtype=float32) - tf.Tensor(0.0013884273, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0021065164, shape=(), dtype=float32) - tf.Tensor(0.32576597, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q88Ppt5Dh9yb",
        "outputId": "96c35101-ce0a-4141-fcef-8220f344e7b4"
      },
      "source": [
        "for i in range(len(tf_predictions)):\r\n",
        "  print(tf_predictions[i][label[i]].numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.99522\n",
            "0.9875257\n",
            "0.44692346\n",
            "0.450415\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBDcRsbWt74i"
      },
      "source": [
        "Also, with the code above, you can predict as many reviews as possible.\r\n",
        "\r\n",
        "# Congratulations\r\n",
        "\r\n",
        "You have successfully built a transformers network with a pre-trained BERT model and achieved ~93% accuracy on the newsgroups classification analysis of the 20 Newsgroup reviews dataset! If you are curious about saving your model, I would like to direct you to the [Keras Documentation](https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model). After all, to efficiently use an API, one must learn how to read and use the documentation."
      ]
    }
  ]
}