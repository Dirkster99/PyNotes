{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "63 Transformer 4 Language Classification MultiClass.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPG1T8+GcDZEF0LJ8ky4wug",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dirkster99/PyNotes/blob/master/Transformers/LocalModelUsage_Finetuning/63_Transformer_4_Language_Classification_MultiClass.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDLTyAriDDLg",
        "outputId": "2dbf455f-3450-4a08-d214-17aa87753ae8"
      },
      "source": [
        "!pip install transformers==4.2.1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==4.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/40/866cbfac4601e0f74c7303d533a9c5d4a53858bd402e08e3e294dd271f25/transformers-4.2.1-py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1) (2.23.0)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/36/59e4a62254c5fcb43894c6b0e9403ec6f4238cc2422a003ed2e6279a1784/tokenizers-0.9.4-cp37-cp37m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 17.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1) (3.7.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 38.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1) (2019.12.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.1) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.1) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.2.1) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.2.1) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.2.1) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.2.1) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.2.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.2.1) (1.0.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=df8219c838679a11c8ef2a4ed642bd0c3b71bb298affeb8934d4f2b6b32b7697\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ia9W-HzFDaub"
      },
      "source": [
        "# Six steps towards building a Language Classification Model with Transformers and TensorFlow 2.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJql3VeHD7Nn"
      },
      "source": [
        "Original Author: James Briggs\r\n",
        "https://www.youtube.com/watch?v=GYDFBfx8Ts8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzlppuarDagD"
      },
      "source": [
        "## Download and Preprocessing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJBaeUYAE4qd"
      },
      "source": [
        "### 20 News Groups Categorization Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXw-mgikFgen",
        "outputId": "d1d1c09b-ceeb-43ba-ecfa-1f7194fa5795"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNCAQBZpFgep",
        "outputId": "275b0ab2-2c69-4ea0-dd03-53d9880a9abd"
      },
      "source": [
        "dataPath = '/gdrive/MyDrive/Colab Notebooks/20_Newsgroups TextClassification/data/'\n",
        "!ls {dataPath.replace(' ', '\\ ')}"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20news-bydate\t      20_newsgroups_data.csv\t\t   model\n",
            "20news-bydate.tar.gz  20_newsgroups_data_no_filenames.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dhrAIBSQGG1X",
        "outputId": "10cef4df-7b8e-4605-f8eb-03c96c1c2e93"
      },
      "source": [
        "import pandas as pd\r\n",
        "df = pd.read_csv(dataPath + '20_newsgroups_data_no_filenames.csv', sep='|')\r\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>news</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rec.sport.baseball</td>\n",
              "      <td>From: cubbie@garnet.berkeley.edu (            ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "      <td>From: gnelson@pion.rutgers.edu (Gregory Nelson...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sci.crypt</td>\n",
              "      <td>From: crypt-comments@math.ncsu.edu\\nSubject: C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>alt.atheism</td>\n",
              "      <td>From: keith@cco.caltech.edu (Keith Allan Schne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "      <td>From: taihou@chromium.iss.nus.sg (Tng Tai Hou)...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                category                                               news\n",
              "0     rec.sport.baseball  From: cubbie@garnet.berkeley.edu (            ...\n",
              "1  comp.sys.mac.hardware  From: gnelson@pion.rutgers.edu (Gregory Nelson...\n",
              "2              sci.crypt  From: crypt-comments@math.ncsu.edu\\nSubject: C...\n",
              "3            alt.atheism  From: keith@cco.caltech.edu (Keith Allan Schne...\n",
              "4  comp.sys.mac.hardware  From: taihou@chromium.iss.nus.sg (Tng Tai Hou)..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgHYZu7eLtw2",
        "outputId": "e72cd714-54f3-4b2d-e703-22e7c77334e9"
      },
      "source": [
        "# Generate number representation for category field\r\n",
        "df['label'] = pd.Categorical(df.category, ordered=True).codes\r\n",
        "df['label'].unique()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 9,  4, 11,  0,  5, 13, 12, 17, 10,  6,  7,  2,  8, 14,  1,  3, 16,\n",
              "       18, 19, 15], dtype=int8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JY7qevRYLtea",
        "outputId": "2de4909a-0ff0-4bc9-9f6e-a40df89830df"
      },
      "source": [
        "# Map labels to humand readable category inside a dictionary\r\n",
        "mapLabels = pd.DataFrame(df.groupby(['category', 'label']).count())\r\n",
        "\r\n",
        "#drop count column\r\n",
        "mapLabels.drop(['news'], axis = 1, inplace = True)\r\n",
        "label2Index = mapLabels.to_dict(orient='index')\r\n",
        "\r\n",
        "print (f\"label2Index :{label2Index}\")\r\n",
        "print (type(label2Index))\r\n",
        "#print (f\"index2Label :{index2Label}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label2Index :{('alt.atheism', 0): {}, ('comp.graphics', 1): {}, ('comp.os.ms-windows.misc', 2): {}, ('comp.sys.ibm.pc.hardware', 3): {}, ('comp.sys.mac.hardware', 4): {}, ('comp.windows.x', 5): {}, ('misc.forsale', 6): {}, ('rec.autos', 7): {}, ('rec.motorcycles', 8): {}, ('rec.sport.baseball', 9): {}, ('rec.sport.hockey', 10): {}, ('sci.crypt', 11): {}, ('sci.electronics', 12): {}, ('sci.med', 13): {}, ('sci.space', 14): {}, ('soc.religion.christian', 15): {}, ('talk.politics.guns', 16): {}, ('talk.politics.mideast', 17): {}, ('talk.politics.misc', 18): {}, ('talk.religion.misc', 19): {}}\n",
            "<class 'dict'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGuO3TWvL6Nq",
        "outputId": "88d6c0b9-c856-4314-cb5e-71ed01621164"
      },
      "source": [
        "# generate inverse dictionary to map in both directions\r\n",
        "index2label = {}\r\n",
        "\r\n",
        "for key in label2Index:\r\n",
        "  print (f\"{key[1]} -> {key[0]}\")\r\n",
        "  index2label[key[1]] = key[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 -> alt.atheism\n",
            "1 -> comp.graphics\n",
            "2 -> comp.os.ms-windows.misc\n",
            "3 -> comp.sys.ibm.pc.hardware\n",
            "4 -> comp.sys.mac.hardware\n",
            "5 -> comp.windows.x\n",
            "6 -> misc.forsale\n",
            "7 -> rec.autos\n",
            "8 -> rec.motorcycles\n",
            "9 -> rec.sport.baseball\n",
            "10 -> rec.sport.hockey\n",
            "11 -> sci.crypt\n",
            "12 -> sci.electronics\n",
            "13 -> sci.med\n",
            "14 -> sci.space\n",
            "15 -> soc.religion.christian\n",
            "16 -> talk.politics.guns\n",
            "17 -> talk.politics.mideast\n",
            "18 -> talk.politics.misc\n",
            "19 -> talk.religion.misc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuHEbKFhL6Tn",
        "outputId": "498cc6e7-53a4-4e83-b188-387dbe3b6a39"
      },
      "source": [
        "label2Index = {v: k for k, v in index2label.items()}\r\n",
        "\r\n",
        "print (f'label2Index: {label2Index}')\r\n",
        "print (f'index2label: {index2label}')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label2Index: {'alt.atheism': 0, 'comp.graphics': 1, 'comp.os.ms-windows.misc': 2, 'comp.sys.ibm.pc.hardware': 3, 'comp.sys.mac.hardware': 4, 'comp.windows.x': 5, 'misc.forsale': 6, 'rec.autos': 7, 'rec.motorcycles': 8, 'rec.sport.baseball': 9, 'rec.sport.hockey': 10, 'sci.crypt': 11, 'sci.electronics': 12, 'sci.med': 13, 'sci.space': 14, 'soc.religion.christian': 15, 'talk.politics.guns': 16, 'talk.politics.mideast': 17, 'talk.politics.misc': 18, 'talk.religion.misc': 19}\n",
            "index2label: {0: 'alt.atheism', 1: 'comp.graphics', 2: 'comp.os.ms-windows.misc', 3: 'comp.sys.ibm.pc.hardware', 4: 'comp.sys.mac.hardware', 5: 'comp.windows.x', 6: 'misc.forsale', 7: 'rec.autos', 8: 'rec.motorcycles', 9: 'rec.sport.baseball', 10: 'rec.sport.hockey', 11: 'sci.crypt', 12: 'sci.electronics', 13: 'sci.med', 14: 'sci.space', 15: 'soc.religion.christian', 16: 'talk.politics.guns', 17: 'talk.politics.mideast', 18: 'talk.politics.misc', 19: 'talk.religion.misc'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Crrzuh66bsgT"
      },
      "source": [
        "# Remoe Email address to avoid additional noise\r\n",
        "df.news.replace(r'[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+', '', regex=True, inplace=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4YNoaoDaK5v"
      },
      "source": [
        "df.rename(columns = {'label' : 'labels', 'news' : 'text'}, inplace = True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlfQrabQ0XJc"
      },
      "source": [
        "df = df[['text','labels']]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "RMkmS0d-aKuX",
        "outputId": "e4037f04-8445-4ae9-8609-9d4cd3d04753"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From:  (                               )\\nSubj...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From:  (Gregory Nelson)\\nSubject: Thanks Apple...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From: \\nSubject: Cryptography FAQ 10/10 - Refe...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>From:  (Keith Allan Schneider)\\nSubject: Re: &lt;...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From:  (Tng Tai Hou)\\nSubject: ADB and graphic...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  labels\n",
              "0  From:  (                               )\\nSubj...       9\n",
              "1  From:  (Gregory Nelson)\\nSubject: Thanks Apple...       4\n",
              "2  From: \\nSubject: Cryptography FAQ 10/10 - Refe...      11\n",
              "3  From:  (Keith Allan Schneider)\\nSubject: Re: <...       0\n",
              "4  From:  (Tng Tai Hou)\\nSubject: ADB and graphic...       4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkInWDIsM7r9"
      },
      "source": [
        "# Drop duplicates to avoid pulliting the test data set with previously seen training data\r\n",
        "# when doing a simple test/train split on 1 file instead of using 2 files\r\n",
        "# df.drop_duplicates(subset='text', keep='first', inplace=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpI1pKfuNXcq",
        "outputId": "ab7d48db-002f-43e9-af66-a532c4d41be3"
      },
      "source": [
        "df.count()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text      11270\n",
              "labels    11270\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "es4IJmHsIBXO",
        "outputId": "6701e22f-f38f-4b19-afe3-ab14358d7684"
      },
      "source": [
        "print (f\"There are {df['labels'].nunique()} unique values {df['labels'].unique()} in the 'labels' column.\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 20 unique values [ 9  4 11  0  5 13 12 17 10  6  7  2  8 14  1  3 16 18 19 15] in the 'labels' column.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "442PUgfzOSuB"
      },
      "source": [
        "### One Hot Encode a continues label value (eg. 0-4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JA_9YivAOQrr",
        "outputId": "053b214b-b2d2-41bf-f613-45341445a7df"
      },
      "source": [
        "arr = df['labels'].values\r\n",
        "arr.size"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11270"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOSaKmwcQIso",
        "outputId": "8acb973b-e588-43cd-f4e6-243900236d78"
      },
      "source": [
        "arr.max()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDtwPC9bOQbB",
        "outputId": "7a8a1639-0d15-4e15-aedb-f751f7bc8ba6"
      },
      "source": [
        "import numpy as np\r\n",
        "labels = np.zeros((arr.size, arr.max() + 1), dtype=int)\r\n",
        "labels.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11270, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oo0Z-IpOQSM",
        "outputId": "addfb54f-385a-43cd-9ae4-ba7c3110cd78"
      },
      "source": [
        "labels[np.arange(arr.size), arr] = 1\r\n",
        "labels.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11270, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ac-SymDrQydJ",
        "outputId": "5ba84dfc-e0bd-4c12-8787-1c8c81d4fba2"
      },
      "source": [
        "for i in range(0, 20):\r\n",
        "  print(labels[i])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RF_cC0RRtjU"
      },
      "source": [
        "### Encode Text Input Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wU3RStSNpjl"
      },
      "source": [
        "seqlen = df['text'].apply(lambda x: len(x.split()))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5itCuhEN76l"
      },
      "source": [
        "import seaborn as sns\r\n",
        "import matplotlib as plt"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "m_XxlXwqOJyQ",
        "outputId": "d960875c-aede-4ca1-dca7-1353288f80a7"
      },
      "source": [
        "# Do a distribution plot on the seqquence length's of the given text\r\n",
        "sns.set_style('darkgrid')\r\n",
        "plt.figure.Figure(figsize=(16,10))\r\n",
        "sns.displot(seqlen)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7f9459b02b50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrGoSQ3HQogV"
      },
      "source": [
        "# Maximum length of the text we are going to train and predict here\r\n",
        "SEQ_LEN = 300"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwphaSBgDaPF"
      },
      "source": [
        "## Encode Input Data\r\n",
        "Encode the Input-Tensor and the Attention Tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1ZOtg_fRA9E"
      },
      "source": [
        "from transformers import AutoTokenizer\r\n",
        "tranformersPreTrainedModelName = 'bert-base-uncased'\r\n",
        "tokenizer = AutoTokenizer.from_pretrained(tranformersPreTrainedModelName) "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-K1gSSpR7J-"
      },
      "source": [
        "tokens = tokenizer.encode_plus('Hello World'\r\n",
        "                               ,max_length = SEQ_LEN          # Using text with this max length\r\n",
        "                               ,truncation=True               # truncate any text longer than max_length\r\n",
        "                               ,padding='max_length'          # padd text that is smaller than max_length\r\n",
        "                               ,add_special_tokens=True       # add special tokens for start, end of sentence, unknown, and mask tokens\r\n",
        "                               ,return_token_type_ids = False # do not return ids for types of tokens\r\n",
        "                               ,return_attention_mask = True\r\n",
        "                               ,return_tensors='tf')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aftNX-1R7GR",
        "outputId": "89caec63-2730-41b3-cf6b-f82dc044539a"
      },
      "source": [
        "# Outputs 2 tensors named 'input_ids' & 'attention_mask'\r\n",
        "# The values 101 and 102 are start and end of sentence identifiers\r\n",
        "# while 7592 & 2088 are tokens for 'Hello World'\r\n",
        "#\r\n",
        "# Attention Mask tells Bert which tokens to pay attention to and which to ompletely ignore\r\n",
        "print (tokens)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input_ids': <tf.Tensor: shape=(1, 300), dtype=int32, numpy=\n",
            "array([[ 101, 7592, 2088,  102,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 300), dtype=int32, numpy=\n",
            "array([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6KLOlPgWfGU"
      },
      "source": [
        "### Tokenize each Sample in Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbEgLLWER63t"
      },
      "source": [
        "import numpy as np\r\n",
        "# initialize numpy arrays for Token-Ids and Attention Masks\r\n",
        "Xids = np.zeros((len(df), SEQ_LEN), dtype=int)\r\n",
        "Xmask = np.zeros((len(df), SEQ_LEN), dtype=int)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ywb5Pi_XGEw",
        "outputId": "9ff7ff26-815f-4d8b-ec4a-ab57bd086c52"
      },
      "source": [
        "Xids.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11270, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNLh-Ir3XGA1"
      },
      "source": [
        "# Use a simple for loop to encode all data points\r\n",
        "for i, sequence in enumerate(df['text']):\r\n",
        "  tokens = tokenizer.encode_plus(sequence\r\n",
        "                               ,max_length = SEQ_LEN          # Using text with this max length\r\n",
        "                               ,truncation=True               # truncate any text longer than max_length\r\n",
        "                               ,padding='max_length'          # padd text that is smaller than max_length\r\n",
        "                               ,add_special_tokens=True       # add special tokens for start, end of sentence, unknown, and mask tokens\r\n",
        "                               ,return_token_type_ids = False # do not return ids for types of tokens\r\n",
        "                               ,return_attention_mask = True\r\n",
        "                               ,return_tensors='tf')\r\n",
        "  \r\n",
        "  Xids[i, :], Xmask[i, :] = tokens['input_ids'], tokens['attention_mask']"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8VQM0QXXF9Z",
        "outputId": "4e360db8-4142-4bf4-d8ef-131068adfb07"
      },
      "source": [
        "# Array of tokenized Ids\r\n",
        "Xids"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 101, 2013, 1024, ...,    0,    0,    0],\n",
              "       [ 101, 2013, 1024, ..., 2151, 1997,  102],\n",
              "       [ 101, 2013, 1024, ..., 1998, 4556,  102],\n",
              "       ...,\n",
              "       [ 101, 2013, 1024, ..., 1011, 1011,  102],\n",
              "       [ 101, 2013, 1024, ..., 1037, 2261,  102],\n",
              "       [ 101, 2013, 1024, ...,    0,    0,    0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0G0SwXjXF6B",
        "outputId": "318c48ac-0de4-41fc-be91-709b151fae6e"
      },
      "source": [
        "# Array of attaention masks\r\n",
        "Xmask"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 1, 1, 1],\n",
              "       [1, 1, 1, ..., 1, 1, 1],\n",
              "       ...,\n",
              "       [1, 1, 1, ..., 1, 1, 1],\n",
              "       [1, 1, 1, ..., 1, 1, 1],\n",
              "       [1, 1, 1, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsjMLMySfoz1"
      },
      "source": [
        "### Save Tokenized Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2q54RC2fslb"
      },
      "source": [
        "with open ('xids.npy', 'wb') as f:\r\n",
        "  np.save(f, Xids)\r\n",
        "with open ('xmask.npy', 'wb') as f:\r\n",
        "  np.save(f, Xmask)\r\n",
        "with open ('labels.npy', 'wb') as f:\r\n",
        "  np.save(f, labels)\r\n",
        "\r\n",
        "del df, Xids, Xmask, labels\r\n",
        "df = None"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_HLCQX0DaTO"
      },
      "source": [
        "## Ininitializing Hugging Face Tokenizer and Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwRV4SBIgSqF"
      },
      "source": [
        "### Load Tokenized Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAe-0GqEgRml"
      },
      "source": [
        "import numpy as np\r\n",
        "with open ('xids.npy', 'rb') as f:\r\n",
        "  Xids = np.load(f)\r\n",
        "with open ('xmask.npy', 'rb') as f:\r\n",
        "  Xmask = np.load(f)\r\n",
        "with open ('labels.npy', 'rb') as f:\r\n",
        "  labels = np.load(f)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fb0tM3ANgpJk",
        "outputId": "98496acb-a468-4b61-8b19-492a73c53b94"
      },
      "source": [
        "Xids"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 101, 2013, 1024, ...,    0,    0,    0],\n",
              "       [ 101, 2013, 1024, ..., 2151, 1997,  102],\n",
              "       [ 101, 2013, 1024, ..., 1998, 4556,  102],\n",
              "       ...,\n",
              "       [ 101, 2013, 1024, ..., 1011, 1011,  102],\n",
              "       [ 101, 2013, 1024, ..., 1037, 2261,  102],\n",
              "       [ 101, 2013, 1024, ...,    0,    0,    0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtJBX_YdVVXq",
        "outputId": "1ecb2f55-0e9f-44dc-9908-dbc4dbc74b5e"
      },
      "source": [
        "for i in range(0, 20):\r\n",
        "  print(labels[i])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYBiX8dEg1e5"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "#tf.config.list_physical_device('GPU')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iy2rA94VhcmM"
      },
      "source": [
        "# TensorFlow expects input and target labels as an input tuple\r\n",
        "# Bert expects a dictionary of 'input_ids' and 'attention_mask' as input\r\n",
        "# So, lets create the dataset object\r\n",
        "# This creates a generator for a tuple of input tokens, attention_masks, and target labels\r\n",
        "dataset = tf.data.Dataset.from_tensor_slices((Xids, Xmask, labels))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uWyj0KkieMk",
        "outputId": "57ec84af-f67a-44e0-95c9-68409c4a6e9b"
      },
      "source": [
        "# View a single row in the dataset\r\n",
        "print (dataset.take(1))\r\n",
        "print ()\r\n",
        "for i in dataset.take(1):\r\n",
        "  print (i)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<TakeDataset shapes: ((300,), (300,), (20,)), types: (tf.int64, tf.int64, tf.int64)>\n",
            "\n",
            "(<tf.Tensor: shape=(300,), dtype=int64, numpy=\n",
            "array([  101,  2013,  1024,  1006,  1007,  3395,  1024,  2128,  1024,\n",
            "       12469,  2369, 27055,  1029,  2129,  1029,  3720,  1011,  1045,\n",
            "        1012,  1040,  1012,  1024, 12943,  3686,  1012,  1015, 13876,\n",
            "       28154,  2475,  1002,  1042,  2683,  2050,  3029,  1024,  2118,\n",
            "        1997,  2662,  1010,  8256,  3210,  1024,  2260,  1050,  3372,\n",
            "        2361,  1011, 14739,  1011,  3677,  1024, 11721, 26573,  1012,\n",
            "        8256,  1012,  3968,  2226,  7009,  1024,  5253,  1998, 22789,\n",
            "        2097,  2031,  3690,  1005,  1055,  1015,  2448,  3020,  2084,\n",
            "        2197,  2095,  1010,  1998,  1996, 12469,  2097,  2022, 28781,\n",
            "        1998,  2025,  6510,  5292, 25074,  2100,  2004,  2172,  2004,\n",
            "        7632, 22414,  4103,  1012, 19371,  2180,  1005,  1056,  2022,\n",
            "        2204,  1006,  1045,  2228,  2002,  1005,  1055,  1037, 16054,\n",
            "        8070,  1007,  2023,  2161,  2061,  2521,  1010,  5253,  1998,\n",
            "       22789,  3271,  2000,  2599,  1996, 12469,  2012,  2327,  1999,\n",
            "        3690,  1010,  2130,  2488,  2084,  1996,  9963,  2012,  5865,\n",
            "        1012, 12469,  3690,  2012,  1014,  1012,  5709,  2575,  2096,\n",
            "       13980,  2012,  1014,  1012,  5709,  2683,  1012,  2057,  2113,\n",
            "        2009,  2003,  2220,  1999,  1996,  2161,  1010,  2057, 12469,\n",
            "        4599,  2031,  4342,  2129,  2000,  5959,  1996,  2460, 10911,\n",
            "        2096,  2009,  2003,  2145,  2045,  1012,   102,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0])>, <tf.Tensor: shape=(300,), dtype=int64, numpy=\n",
            "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])>, <tf.Tensor: shape=(20,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZobIL-pRjEjd"
      },
      "source": [
        "# minute 21:55\r\n",
        "# TensorFlow Bert model expects our input in a Tuple format containing:\r\n",
        "# 1) 'input_ids' and 'attention_mask' in a Dictionary and\r\n",
        "# 2) a label as 2nd part of the tupel\r\n",
        "def map_func(input_ids, masks, labels):\r\n",
        "  return {'input_ids': input_ids, 'attention_mask': masks}, labels"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-_aS7QR4eS9"
      },
      "source": [
        "# we can use the dataset map function to apply this format\r\n",
        "dataset = dataset.map(map_func)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lMhzkmz4vtO",
        "outputId": "1019da01-5e39-46f7-f823-a82ec3160f6e"
      },
      "source": [
        "# View a single row in the dataset\r\n",
        "print (dataset.take(1))\r\n",
        "print ()\r\n",
        "for i in dataset.take(1):\r\n",
        "  print (i)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<TakeDataset shapes: ({input_ids: (300,), attention_mask: (300,)}, (20,)), types: ({input_ids: tf.int64, attention_mask: tf.int64}, tf.int64)>\n",
            "\n",
            "({'input_ids': <tf.Tensor: shape=(300,), dtype=int64, numpy=\n",
            "array([  101,  2013,  1024,  1006,  1007,  3395,  1024,  2128,  1024,\n",
            "       12469,  2369, 27055,  1029,  2129,  1029,  3720,  1011,  1045,\n",
            "        1012,  1040,  1012,  1024, 12943,  3686,  1012,  1015, 13876,\n",
            "       28154,  2475,  1002,  1042,  2683,  2050,  3029,  1024,  2118,\n",
            "        1997,  2662,  1010,  8256,  3210,  1024,  2260,  1050,  3372,\n",
            "        2361,  1011, 14739,  1011,  3677,  1024, 11721, 26573,  1012,\n",
            "        8256,  1012,  3968,  2226,  7009,  1024,  5253,  1998, 22789,\n",
            "        2097,  2031,  3690,  1005,  1055,  1015,  2448,  3020,  2084,\n",
            "        2197,  2095,  1010,  1998,  1996, 12469,  2097,  2022, 28781,\n",
            "        1998,  2025,  6510,  5292, 25074,  2100,  2004,  2172,  2004,\n",
            "        7632, 22414,  4103,  1012, 19371,  2180,  1005,  1056,  2022,\n",
            "        2204,  1006,  1045,  2228,  2002,  1005,  1055,  1037, 16054,\n",
            "        8070,  1007,  2023,  2161,  2061,  2521,  1010,  5253,  1998,\n",
            "       22789,  3271,  2000,  2599,  1996, 12469,  2012,  2327,  1999,\n",
            "        3690,  1010,  2130,  2488,  2084,  1996,  9963,  2012,  5865,\n",
            "        1012, 12469,  3690,  2012,  1014,  1012,  5709,  2575,  2096,\n",
            "       13980,  2012,  1014,  1012,  5709,  2683,  1012,  2057,  2113,\n",
            "        2009,  2003,  2220,  1999,  1996,  2161,  1010,  2057, 12469,\n",
            "        4599,  2031,  4342,  2129,  2000,  5959,  1996,  2460, 10911,\n",
            "        2096,  2009,  2003,  2145,  2045,  1012,   102,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0])>, 'attention_mask': <tf.Tensor: shape=(300,), dtype=int64, numpy=\n",
            "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])>}, <tf.Tensor: shape=(20,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMkNHhxq47Ze"
      },
      "source": [
        "# SHuffle and Bach Dataset\r\n",
        "dataset = dataset.shuffle(1000).batch(32)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00o88BAS5YKh",
        "outputId": "0f424aaf-4323-4d13-925c-656a75d5fdcf"
      },
      "source": [
        "# Get the total size of dataset now that it is batched\r\n",
        "#\r\n",
        "# the dataset object is a generator object so we cannot take the length of it directly\r\n",
        "# thus, we have to convert it into a list\r\n",
        "# \r\n",
        "# Do not do this with a very large dataset\r\n",
        "#\r\n",
        "DS_LEN = len(list(dataset))\r\n",
        "DS_LEN"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "353"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WK8di-Y45rrq",
        "outputId": "1ed8dee7-46a8-4951-9f07-e54958c7cf20"
      },
      "source": [
        "print (f\"Alternative Computation for DS_LEN: {len(Xids)/32} -> {round(len(Xids)/32, 0)}\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Alternative Computation for DS_LEN: 352.1875 -> 352.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSB_T17u834a"
      },
      "source": [
        "SPLIT = .9\r\n",
        "\r\n",
        "# take or skip the specified number of batches to split by factor\r\n",
        "train = dataset.take(round(DS_LEN * SPLIT))\r\n",
        "evalu = dataset.skip(round(DS_LEN * SPLIT))\r\n",
        "\r\n",
        "del dataset"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTZP1_udDaF_"
      },
      "source": [
        "## Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLCtrOdj9PKj"
      },
      "source": [
        "from transformers import BertConfig\r\n",
        "bertConfig = BertConfig.from_pretrained(tranformersPreTrainedModelName\r\n",
        "                                        , output_hidden_states=True\r\n",
        "                                        , num_lables=6\r\n",
        "                                        , max_length=SEQ_LEN)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPGGoaJ39tjz",
        "outputId": "bdc4ff41-7ba6-4ff1-b7fe-6369f95bd941"
      },
      "source": [
        "from transformers import TFBertForSequenceClassification\r\n",
        "tranformersPreTrainedModelName = 'bert-base-uncased'\r\n",
        "bert = TFBertForSequenceClassification.from_pretrained(tranformersPreTrainedModelName, config=bertConfig)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIxfUZuK9DVR",
        "outputId": "c24b38be-ad2a-48b9-b38c-804ed9009279"
      },
      "source": [
        "bert.summary()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"tf_bert_for_sequence_classification_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bert (TFBertMainLayer)       multiple                  109482240 \n",
            "_________________________________________________________________\n",
            "dropout_75 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "classifier (Dense)           multiple                  1538      \n",
            "=================================================================\n",
            "Total params: 109,483,778\n",
            "Trainable params: 109,483,778\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJsrgwyO9tcF"
      },
      "source": [
        "loss = tf.keras.losses.BinaryCrossentropy()\r\n",
        "optimizer = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\r\n",
        "bert.compile(\r\n",
        "    loss=loss,\r\n",
        "    optimizer=optimizer,\r\n",
        "    metrics=['accuracy']\r\n",
        "    )"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_eK-NlO99DR3",
        "outputId": "0a958994-2ac6-44e2-a509-cca830d98f41"
      },
      "source": [
        "from timeit import default_timer as timer\r\n",
        "from datetime import timedelta\r\n",
        "\r\n",
        "start = timer()\r\n",
        "\r\n",
        "history = bert.fit(train, validation_data=evalu, epochs=6)\r\n",
        "\r\n",
        "end = timer()\r\n",
        "print(timedelta(seconds=end-start))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-1ed72a0d4fbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevalu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:756 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/compile_utils.py:203 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/losses.py:152 __call__\n        losses = call_fn(y_true, y_pred)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/losses.py:256 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/losses.py:1608 binary_crossentropy\n        K.binary_crossentropy(y_true, y_pred, from_logits=from_logits), axis=-1)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:4994 binary_crossentropy\n        bce = target * math_ops.log(output + epsilon())\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1180 binary_op_wrapper\n        raise e\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1164 binary_op_wrapper\n        return func(x, y, name=name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1496 _mul_dispatch\n        return multiply(x, y, name=name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:518 multiply\n        return gen_math_ops.mul(x, y, name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:6078 mul\n        \"Mul\", x=x, y=y, name=name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:750 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py:592 _create_op_internal\n        compute_device)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:3536 _create_op_internal\n        op_def=op_def)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:2016 __init__\n        control_input_ops, op_def)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:1856 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 20 and 768 for '{{node binary_crossentropy/mul}} = Mul[T=DT_FLOAT](binary_crossentropy/Cast, binary_crossentropy/Log)' with input shapes: [?,20], [?,300,768].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CW5lY7KF_2G0"
      },
      "source": [
        ""
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gst4JKJC_2OB"
      },
      "source": [
        ""
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1x8td4l_2Td"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIkkv4-n9DOD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfLkKNIt9DKm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}