{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SparkNLP Advanced Hellow World.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMlDC9OfMxza3ljsTFacTBC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dirkster99/PyNotes/blob/master/PySpark_SparkNLP/SparkNLP_Advanced_Hellow_World.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQSftVQM_sJ3"
      },
      "source": [
        "# Spark NLP Advanced Hello World\n",
        "\n",
        "This notebook was created from this youtube video\n",
        "Source: https://www.youtube.com/watch?v=fEU37G70SFc\n",
        "\n",
        "and explains some basic/advanced concepts in SparkNLP."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qg9Dj-8u_m2l",
        "outputId": "3c09a152-7a3f-46d9-9f65-53ee1150eb18"
      },
      "source": [
        "# This is only to setup PySpark and Spark NLP on Colab\n",
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-08 20:21:46--  http://setup.johnsnowlabs.com/colab.sh\n",
            "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
            "--2021-06-08 20:21:46--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1608 (1.6K) [text/plain]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>]   1.57K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-06-08 20:21:46 (30.6 MB/s) - written to stdout [1608/1608]\n",
            "\n",
            "setup Colab for PySpark 3.0.2 and Spark NLP 3.1.0\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:7 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:9 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:10 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [61.8 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:13 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Ign:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [800 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:16 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,184 kB]\n",
            "Hit:18 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,770 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [450 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,414 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,616 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,184 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [33.5 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [480 kB]\n",
            "Get:26 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [906 kB]\n",
            "Get:27 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [40.9 kB]\n",
            "Fetched 13.2 MB in 4s (2,941 kB/s)\n",
            "Reading package lists... Done\n",
            "\u001b[K     |████████████████████████████████| 204.8MB 75kB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 5.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 57.7MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaeNCMEu_w6Z"
      },
      "source": [
        "import sparknlp\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shAXgCKV___M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "14ba4351-dd4b-4c37-b602-7a064f2571fe"
      },
      "source": [
        "spark = sparknlp.start()\n",
        "spark"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://89f492f7186e:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.0.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f2db08899d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX5ihOS6AEjp"
      },
      "source": [
        "data = spark.createDataFrame([['Peter is a good person living in Germny and writting an e-mail. Paula is also a good person. She lives in London.']]).toDF('text')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0tzOsOiAUeZ",
        "outputId": "578ce3af-9f98-4768-dfd1-fb102faa5fc0"
      },
      "source": [
        "data.show(truncate=False)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------------------------------------------------------------------------------------------------+\n",
            "|text                                                                                                             |\n",
            "+-----------------------------------------------------------------------------------------------------------------+\n",
            "|Peter is a good person living in Germny and writting an e-mail. Paula is also a good person. She lives in London.|\n",
            "+-----------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2UEOObGAZ0P"
      },
      "source": [
        "# DocumentAssembler controls cleaning up of source text and handling of special characters and new lines through 'cleanupMode'\n",
        "document = DocumentAssembler().setInputCol('text').setOutputCol('document').setCleanupMode('shrink')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XG9TVj4PBLaI"
      },
      "source": [
        "# Sentence Detector splits text into sentences in a meaningful way\n",
        "sentence = SentenceDetector().setInputCols(['document']).setOutputCol('sentence')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6KdP-eNB7JX",
        "outputId": "522dc2b0-d549-425c-93ce-b5f7186cdb18"
      },
      "source": [
        "# sentence.explodeSentences() explodes sentences improves parallelism in large text concentration\n",
        "sentence.setExplodeSentences(True) # will put each sentence on a different dataFrame row"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentenceDetector_1c19aff676e2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLp9q09jCubq"
      },
      "source": [
        "# Tokenizer splits sentences into neaningful words for later NLP\n",
        "# Always use the sentence output rather than the document if you have a SentenceDetector\n",
        "tokenizer = Tokenizer().setInputCols(['sentence']).setOutputCol('token')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G88FZjK9DVn-",
        "outputId": "75591b75-ce3a-4641-aa14-7987ce0df315"
      },
      "source": [
        "# tokenizer.setExceptions()   Configures tokens that we don't want to split\n",
        "# tokenizer.setContextChars() Configures characters we want to remove from our tokens\n",
        "# tokenizer.splitChars()      Configure splitting by a certain character\n",
        "# tokenizer.splitPattern()    Configure splitting by a certain pattern etc...\n",
        "\n",
        "tokenizer.setExceptions(['e-mail']) # Configures tokens that we don't want to split"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tokenizer_166e35b5e808"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48cN4BBcEhfB",
        "outputId": "82ef2ed5-d56d-446e-94ed-d0bfbd1cb9e8"
      },
      "source": [
        "# Spell checker SymmetricDetele or NorvigSweeting: Fix token typos\n",
        "# pretrained() function on AnnotatorModels retrieves free Open Source pretrained models from the Internet\n",
        "checker = NorvigSweetingModel.pretrained().setInputCols(['token']).setOutputCol('checked')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "spellcheck_norvig download started this may take some time.\n",
            "Approximate size to download 4.2 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaOGFy_yLiEv",
        "outputId": "21bd44a1-ec11-4366-9ee8-0c27bdb1527d"
      },
      "source": [
        "# NER requires Embeddings as input - you might get the below error if you provide no embeddings\n",
        "# IllegalArgumentException: requirement failed: Wrong or missing inputCols annotators in NerDLModel_d4424c9af5f4.\n",
        "#\n",
        "# Current inputCols: sentence,checked. Dataset's columns:\n",
        "# (column_name=text,is_nlp_annotator=false)\n",
        "# (column_name=document,is_nlp_annotator=true,type=document)\n",
        "# (column_name=sentence,is_nlp_annotator=true,type=document)\n",
        "# (column_name=token,is_nlp_annotator=true,type=token)\n",
        "# (column_name=checked,is_nlp_annotator=true,type=token).\n",
        "# Make sure such annotators exist in your pipeline, with the right output names and that they have following annotator types: document, token, word_embeddings\n",
        "\n",
        "# There are BERT or WordEmbeddings (GloVe, gensim) - vector representation of tokens\n",
        "embeddings  = WordEmbeddingsModel.pretrained().setInputCols(['sentence','checked']).setOutputCol('embeddings')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "glove_100d download started this may take some time.\n",
            "Approximate size to download 145.3 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vU5k2PppFckG",
        "outputId": "62de285a-6556-4855-e5d4-568549eaf758"
      },
      "source": [
        "# Named Entity Recognition: Identifies entities in text, i.e. a Person or Location\n",
        "# Lets use a TensorFlow Model NerDLModel for that\n",
        "# The NER Model has 3 inputs:\n",
        "# Embeddings    -> 'embeddings'\n",
        "# Document Type -> 'sentence'\n",
        "# Token Type    -> 'token' or 'checked'\n",
        "ner = NerDLModel.pretrained().setInputCols(['sentence', 'checked', 'embeddings']).setOutputCol('ner')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ner_dl download started this may take some time.\n",
            "Approximate size to download 13.6 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvW3atf7GrDl"
      },
      "source": [
        "# Chunk builder, NerConverter: Reads NER input and builds chunks based on labelled data\n",
        "converter = NerConverter().setInputCols(['sentence', 'checked', 'ner']).setOutputCol('chunk')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0Hs4ij3HXzP"
      },
      "source": [
        "# Pipeline a component from Apache Spark ML to build multiple stage machine learning processes\n",
        "from pyspark.ml import Pipeline\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGSZSS5HH_OB"
      },
      "source": [
        "# A simple pipeline, which acts as an estimator.\n",
        "# A Pipeline consists of a sequence of stages, each of which is either an Estimator or a Transformer.\n",
        "# When Pipeline.fit() is called, the stages are executed in order. If a stage is an Estimator, its Estimator.fit() method will be called on the input dataset to fit a model.\n",
        "# Then the model, which is a transformer, will be used to transform the dataset as the input to the next stage.\n",
        "# If a stage is a Transformer, its Transformer.transform() method will be called to produce the dataset for the next stage.\n",
        "# The fitted model from a Pipeline is a PipelineModel, which consists of fitted models and transformers, corresponding to the pipeline stages.\n",
        "# If stages is an empty list, the pipeline acts as an identity transformer.\n",
        "pipeline = Pipeline().setStages([document, sentence, tokenizer, checker, embeddings, ner, converter])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtxvZojKIS8E"
      },
      "source": [
        "# Fit is normally required for training only but it still has to be used for protocol\n",
        "# even if stages are already trained\n",
        "#\n",
        "# The dataframe passed here is in our case irrelevant we could also pass\n",
        "# an empty dataframe since there is not training taking place here\n",
        "#\n",
        "# pipeline.fit() returns a PipelineModel object\n",
        "model = pipeline.fit(data)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-4lARS0KGOU"
      },
      "source": [
        "# transform on a PipelineModel applies the pipeline transformation on to the data\n",
        "result = model.transform(data)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmgCPSFMK-uh",
        "outputId": "2ea8c411-5583-43fa-9701-c87784d1c2b8"
      },
      "source": [
        "result.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|            sentence|               token|             checked|          embeddings|                 ner|               chunk|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|Peter is a good p...|[[document, 0, 11...|[[document, 0, 62...|[[token, 0, 4, Pe...|[[token, 0, 4, Pe...|[[word_embeddings...|[[named_entity, 0...|[[chunk, 0, 4, Pe...|\n",
            "|Peter is a good p...|[[document, 0, 11...|[[document, 64, 9...|[[token, 64, 68, ...|[[token, 64, 68, ...|[[word_embeddings...|[[named_entity, 6...|[[chunk, 64, 68, ...|\n",
            "|Peter is a good p...|[[document, 0, 11...|[[document, 93, 1...|[[token, 93, 95, ...|[[token, 93, 95, ...|[[word_embeddings...|[[named_entity, 9...|[[chunk, 106, 111...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGcsL2mlNOLI",
        "outputId": "b525e039-1381-47bb-eed6-91c82177f733"
      },
      "source": [
        "result.select('sentence.result').show(truncate=False)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------------------------------------------------+\n",
            "|result                                                           |\n",
            "+-----------------------------------------------------------------+\n",
            "|[Peter is a good person living in Germny and writting an e-mail.]|\n",
            "|[Paula is also a good person.]                                   |\n",
            "|[She lives in London.]                                           |\n",
            "+-----------------------------------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJFT1AykO7jo",
        "outputId": "74b7c017-cffe-4d96-c875-21a74197194b"
      },
      "source": [
        "result.select('checked.result').show(truncate=False)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------------------------------------------------------------+\n",
            "|result                                                                       |\n",
            "+-----------------------------------------------------------------------------+\n",
            "|[Peter, is, a, good, person, living, in, Germany, and, writhing, an, e-mail.]|\n",
            "|[Paula, is, also, a, good, person, .]                                        |\n",
            "|[She, lives, in, London, .]                                                  |\n",
            "+-----------------------------------------------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8e-NWLRPM41",
        "outputId": "e30c7099-450f-444f-d826-f2d0ed8334fb"
      },
      "source": [
        "# shows 1 NER label for each token\n",
        "result.select('ner.result', 'checked.result').show(truncate=False)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------------------------------+-----------------------------------------------------------------------------+\n",
            "|result                                      |result                                                                       |\n",
            "+--------------------------------------------+-----------------------------------------------------------------------------+\n",
            "|[B-PER, O, O, O, O, O, O, B-LOC, O, O, O, O]|[Peter, is, a, good, person, living, in, Germany, and, writhing, an, e-mail.]|\n",
            "|[B-PER, O, O, O, O, O, O]                   |[Paula, is, also, a, good, person, .]                                        |\n",
            "|[O, O, O, B-LOC, O]                         |[She, lives, in, London, .]                                                  |\n",
            "+--------------------------------------------+-----------------------------------------------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNKJhCsfPotl",
        "outputId": "e9f465b5-c608-4fab-8a8a-3b9f700dcf91"
      },
      "source": [
        "# get the bounds with this\n",
        "result.select('ner.begin', 'ner.end').show(truncate=False)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------------------------------------+---------------------------------------------+\n",
            "|begin                                        |end                                          |\n",
            "+---------------------------------------------+---------------------------------------------+\n",
            "|[0, 6, 9, 11, 16, 23, 30, 33, 40, 44, 53, 56]|[4, 7, 9, 14, 21, 28, 31, 38, 42, 51, 54, 62]|\n",
            "|[64, 70, 73, 78, 80, 85, 91]                 |[68, 71, 76, 78, 83, 90, 91]                 |\n",
            "|[93, 97, 103, 106, 112]                      |[95, 101, 104, 111, 112]                     |\n",
            "+---------------------------------------------+---------------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyBdng-LQKmz",
        "outputId": "404f4f87-11c8-4766-c2ec-6b0cd49ea825"
      },
      "source": [
        "# NerConverter chuck type output (based on NER)\n",
        "result.select('chunk.result','chunk.begin', 'chunk.end').show(truncate=False)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------+-------+-------+\n",
            "|result         |begin  |end    |\n",
            "+---------------+-------+-------+\n",
            "|[Peter, Germny]|[0, 33]|[4, 38]|\n",
            "|[Paula]        |[64]   |[68]   |\n",
            "|[London]       |[106]  |[111]  |\n",
            "+---------------+-------+-------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8aAob4qQaqy"
      },
      "source": [
        "# LightPipelines are faster Pipelines for small amounts of data on a single machine (Removes Spark Data Frames overhead)\n",
        "light = LightPipeline(model)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74ZYJioQRMBK",
        "outputId": "7da9c747-96d4-420f-d9d2-da49dba17dca"
      },
      "source": [
        "# annotate() functions works really fast with strings or list of strings and returns a dictionary of results\n",
        "resultDict = light.annotate('Bruno is living in Italy, and he is doing well.')\n",
        "resultDict"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'checked': ['Bruno',\n",
              "  'is',\n",
              "  'living',\n",
              "  'in',\n",
              "  'Italy',\n",
              "  ',',\n",
              "  'and',\n",
              "  'he',\n",
              "  'is',\n",
              "  'doing',\n",
              "  'well',\n",
              "  '.'],\n",
              " 'chunk': ['Bruno', 'Italy'],\n",
              " 'document': ['Bruno is living in Italy, and he is doing well.'],\n",
              " 'embeddings': ['Bruno',\n",
              "  'is',\n",
              "  'living',\n",
              "  'in',\n",
              "  'Italy',\n",
              "  ',',\n",
              "  'and',\n",
              "  'he',\n",
              "  'is',\n",
              "  'doing',\n",
              "  'well',\n",
              "  '.'],\n",
              " 'ner': ['B-PER', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
              " 'sentence': ['Bruno is living in Italy, and he is doing well.'],\n",
              " 'token': ['Bruno',\n",
              "  'is',\n",
              "  'living',\n",
              "  'in',\n",
              "  'Italy',\n",
              "  ',',\n",
              "  'and',\n",
              "  'he',\n",
              "  'is',\n",
              "  'doing',\n",
              "  'well',\n",
              "  '.']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "It7WaZIyRfAi"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    }
  ]
}