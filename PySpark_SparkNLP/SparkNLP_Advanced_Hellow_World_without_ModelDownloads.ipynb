{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SparkNLP Advanced Hellow World without ModelDownloads.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOJrpQoNLoOWA3L0EL2KV4B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dirkster99/PyNotes/blob/master/PySpark_SparkNLP/SparkNLP_Advanced_Hellow_World_without_ModelDownloads.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQSftVQM_sJ3"
      },
      "source": [
        "# Spark NLP Advanced Hello World\n",
        "\n",
        "This notebook was created from this youtube video\n",
        "Source: https://www.youtube.com/watch?v=fEU37G70SFc\n",
        "\n",
        "and explains some basic/advanced concepts in SparkNLP.\n",
        "\n",
        "**This is a simplified version of the full video to demonstrate usage without downloading a pre-trained model.** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qg9Dj-8u_m2l",
        "outputId": "8976b0d7-9226-41d2-9ae3-0981af8271a3"
      },
      "source": [
        "# This is only to setup PySpark and Spark NLP on Colab\n",
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-08 20:32:13--  http://setup.johnsnowlabs.com/colab.sh\n",
            "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
            "--2021-06-08 20:32:13--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1608 (1.6K) [text/plain]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>]   1.57K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-06-08 20:32:13 (35.1 MB/s) - written to stdout [1608/1608]\n",
            "\n",
            "setup Colab for PySpark 3.0.2 and Spark NLP 3.1.0\n",
            "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:11 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [450 kB]\n",
            "Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:13 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,414 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,184 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:16 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:17 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [61.8 kB]\n",
            "Hit:18 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Ign:20 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:20 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [800 kB]\n",
            "Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,770 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,184 kB]\n",
            "Get:23 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [906 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [480 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [33.5 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,616 kB]\n",
            "Get:27 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [40.9 kB]\n",
            "Fetched 13.2 MB in 4s (3,578 kB/s)\n",
            "Reading package lists... Done\n",
            "\u001b[K     |████████████████████████████████| 204.8MB 73kB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 4.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 41.6MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaeNCMEu_w6Z"
      },
      "source": [
        "import sparknlp\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shAXgCKV___M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "cc5c24fd-6ba4-4224-fe53-b1240951e14b"
      },
      "source": [
        "spark = sparknlp.start()\n",
        "spark"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://9a956a48ff85:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.0.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f2743769310>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX5ihOS6AEjp"
      },
      "source": [
        "data = spark.createDataFrame([['Peter is a good person living in Germny and writting an e-mail. Paula is also a good person. She lives in London.']]).toDF('text')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0tzOsOiAUeZ",
        "outputId": "b4d3b8c6-e736-41dd-94c6-2dcfa62c9a23"
      },
      "source": [
        "data.show(truncate=False)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------------------------------------------------------------------------------------------------+\n",
            "|text                                                                                                             |\n",
            "+-----------------------------------------------------------------------------------------------------------------+\n",
            "|Peter is a good person living in Germny and writting an e-mail. Paula is also a good person. She lives in London.|\n",
            "+-----------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2UEOObGAZ0P"
      },
      "source": [
        "# DocumentAssembler controls cleaning up of source text and handling of special characters and new lines through 'cleanupMode'\n",
        "document = DocumentAssembler().setInputCol('text').setOutputCol('document').setCleanupMode('shrink')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XG9TVj4PBLaI"
      },
      "source": [
        "# Sentence Detector splits text into sentences in a meaningful way\n",
        "sentence = SentenceDetector().setInputCols(['document']).setOutputCol('sentence')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6KdP-eNB7JX",
        "outputId": "9b95a43e-ec55-4c3e-9296-70c1795fa944"
      },
      "source": [
        "# sentence.explodeSentences() explodes sentences improves parallelism in large text concentration\n",
        "sentence.setExplodeSentences(True) # will put each sentence on a different dataFrame row"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentenceDetector_4492d8de354f"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLp9q09jCubq"
      },
      "source": [
        "# Tokenizer splits sentences into neaningful words for later NLP\n",
        "# Always use the sentence output rather than the document if you have a SentenceDetector\n",
        "tokenizer = Tokenizer().setInputCols(['sentence']).setOutputCol('token')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G88FZjK9DVn-",
        "outputId": "f4a39952-e195-479c-831c-f897234f1e84"
      },
      "source": [
        "# tokenizer.setExceptions()   Configures tokens that we don't want to split\n",
        "# tokenizer.setContextChars() Configures characters we want to remove from our tokens\n",
        "# tokenizer.splitChars()      Configure splitting by a certain character\n",
        "# tokenizer.splitPattern()    Configure splitting by a certain pattern etc...\n",
        "\n",
        "tokenizer.setExceptions(['e-mail']) # Configures tokens that we don't want to split"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tokenizer_c5fd3371bb9b"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0Hs4ij3HXzP"
      },
      "source": [
        "# Pipeline a component from Apache Spark ML to build multiple stage machine learning processes\n",
        "from pyspark.ml import Pipeline\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGSZSS5HH_OB"
      },
      "source": [
        "# A simple pipeline, which acts as an estimator.\n",
        "# A Pipeline consists of a sequence of stages, each of which is either an Estimator or a Transformer.\n",
        "# When Pipeline.fit() is called, the stages are executed in order. If a stage is an Estimator, its Estimator.fit() method will be called on the input dataset to fit a model.\n",
        "# Then the model, which is a transformer, will be used to transform the dataset as the input to the next stage.\n",
        "# If a stage is a Transformer, its Transformer.transform() method will be called to produce the dataset for the next stage.\n",
        "# The fitted model from a Pipeline is a PipelineModel, which consists of fitted models and transformers, corresponding to the pipeline stages.\n",
        "# If stages is an empty list, the pipeline acts as an identity transformer.\n",
        "pipeline = Pipeline().setStages([document, sentence, tokenizer])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtxvZojKIS8E"
      },
      "source": [
        "# Fit is normally required for training only but it still has to be used for protocol\n",
        "# even if stages are already trained\n",
        "#\n",
        "# The dataframe passed here is in our case irrelevant we could also pass\n",
        "# an empty dataframe since there is not training taking place here\n",
        "#\n",
        "# pipeline.fit() returns a PipelineModel object\n",
        "model = pipeline.fit(data)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-4lARS0KGOU"
      },
      "source": [
        "# transform on a PipelineModel applies the pipeline transformation on to the data\n",
        "result = model.transform(data)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmgCPSFMK-uh",
        "outputId": "4719f4e8-ca00-49df-d90f-c60067215979"
      },
      "source": [
        "result.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|            sentence|               token|\n",
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "|Peter is a good p...|[[document, 0, 11...|[[document, 0, 62...|[[token, 0, 4, Pe...|\n",
            "|Peter is a good p...|[[document, 0, 11...|[[document, 64, 9...|[[token, 64, 68, ...|\n",
            "|Peter is a good p...|[[document, 0, 11...|[[document, 93, 1...|[[token, 93, 95, ...|\n",
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGcsL2mlNOLI",
        "outputId": "74be299e-4a5e-4565-b7c5-9dd7e3ccf1f8"
      },
      "source": [
        "result.select('sentence.result').show(truncate=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------------------------------------------------+\n",
            "|result                                                           |\n",
            "+-----------------------------------------------------------------+\n",
            "|[Peter is a good person living in Germny and writting an e-mail.]|\n",
            "|[Paula is also a good person.]                                   |\n",
            "|[She lives in London.]                                           |\n",
            "+-----------------------------------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8aAob4qQaqy"
      },
      "source": [
        "# LightPipelines are faster Pipelines for small amounts of data on a single machine (Removes Spark Data Frames overhead)\n",
        "light = LightPipeline(model)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74ZYJioQRMBK",
        "outputId": "7b346173-9c78-41c6-ea8e-9b0623547cf9"
      },
      "source": [
        "# annotate() functions works really fast with strings or list of strings and returns a dictionary of results\n",
        "resultDict = light.annotate('Bruno is living in Italy, and he is doing well.')\n",
        "resultDict"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'document': ['Bruno is living in Italy, and he is doing well.'],\n",
              " 'sentence': ['Bruno is living in Italy, and he is doing well.'],\n",
              " 'token': ['Bruno',\n",
              "  'is',\n",
              "  'living',\n",
              "  'in',\n",
              "  'Italy',\n",
              "  ',',\n",
              "  'and',\n",
              "  'he',\n",
              "  'is',\n",
              "  'doing',\n",
              "  'well',\n",
              "  '.']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "It7WaZIyRfAi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}