{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TestSparkNLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNK9thZtI1jy",
        "colab_type": "text"
      },
      "source": [
        "# Using SparkNLP, Spark with Tensorflow in Google CoLab\n",
        "\n",
        "The below code was taken from this talk:\n",
        "- [Natural Language Understanding at Scale with Spark Native NLP, Spark ML &TensorFlow](https://www.youtube.com/watch?v=k5X12mdEvb8) by Alex Thomas\n",
        "\n",
        "- The original source of the code lives in [Alex Thomas' repo on GitHub](https://github.com/alexander-n-thomas/sparksummiteunlp)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIRqHI4ImsYg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "f80b9685-146b-4c88-baaf-07e284498be2"
      },
      "source": [
        "# https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/quick_start_google_colab.ipynb\n",
        "import os\n",
        "\n",
        "# Install java\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "! java -version\n",
        "\n",
        "# Install pyspark\n",
        "! pip install --ignore-installed pyspark==2.4.3\n",
        "\n",
        "# Install Spark NLP\n",
        "! pip install --ignore-installed spark-nlp==2.2.2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"1.8.0_222\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_222-8u222-b10-1ubuntu1~18.04.1-b10)\n",
            "OpenJDK 64-Bit Server VM (build 25.222-b10, mixed mode)\n",
            "Collecting pyspark==2.4.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/98/244399c0daa7894cdf387e7007d5e8b3710a79b67f3fd991c0b0b644822d/pyspark-2.4.3.tar.gz (215.6MB)\n",
            "\u001b[K     |████████████████████████████████| 215.6MB 48kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 35.7MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.3-py2.py3-none-any.whl size=215964963 sha256=d3e3cff114f6a2daa538955b71e0d2a8ad85772f9638b5ab8b3aa1630c8427ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/20/f0/b30e2024226dc112e256930dd2cd4f06d00ab053c86278dcf3\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.3\n",
            "Collecting spark-nlp==2.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/f9/1a/711bde42e9cd17b5166a2c282ba9824103c416091c9ad95ca7dcece7170e/spark_nlp-2.2.2-py2.py3-none-any.whl\n",
            "Installing collected packages: spark-nlp\n",
            "Successfully installed spark-nlp-2.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvUie2b6mtxg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "6d9f7e6a-2c1d-444d-fda6-741642b6749b"
      },
      "source": [
        "import sparknlp\n",
        "spark = sparknlp.start(include_ocr=True)\n",
        "\n",
        "print(\"Spark NLP version\")\n",
        "sparknlp.version()\n",
        "print(\"Apache Spark version\")\n",
        "spark.version"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spark NLP version\n",
            "2.2.2\n",
            "Apache Spark version\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.4.3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9KyKPbFnTTw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "outputId": "6064776b-5b09-4ed9-83be-e6777bf9e52c"
      },
      "source": [
        "!pip install BioPython"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting BioPython\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/01/7e5858a1e54bd0bd0d179cd74654740f07e86fb921a43dd20fb8beabe69d/biopython-1.75-cp36-cp36m-manylinux1_x86_64.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 5.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from BioPython) (1.17.4)\n",
            "Installing collected packages: BioPython\n",
            "Successfully installed BioPython-1.75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTEEKHVNrjnA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        },
        "outputId": "ecd1d548-19b1-420a-b9cd-265033f85c3b"
      },
      "source": [
        "from Bio import Entrez, Medline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.utils import resample\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import pyspark\n",
        "from pyspark.ml import Pipeline, feature as spark_ft\n",
        "from pyspark.sql.functions import udf, col\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import DocumentAssembler\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUJrl-lirsBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def query(terms, num_docs=1000):\n",
        "    search_term = '+'.join(terms)\n",
        "    print('Searching PubMed abstracts for documents containing term: ',search_term)\n",
        "    handle = Entrez.esearch(db=\"pubmed\", term=search_term, retmax=num_docs)\n",
        "    record = Entrez.read(handle)\n",
        "    handle.close()\n",
        "    idlist = record[\"IdList\"]\n",
        "    \n",
        "    handle = Entrez.efetch(db=\"pubmed\", id=idlist, rettype=\"medline\",retmode=\"text\")\n",
        "    records = Medline.parse(handle)\n",
        "    data = []\n",
        "    for record in records:\n",
        "        data.append((record.get(\"TI\", \"?\"),record.get(\"AU\", \"?\"),record.get(\"SO\", \"?\"),record.get(\"AB\",\"?\")))\n",
        "\n",
        "    df = pd.DataFrame(data=data, columns=['title','authors','source','text'])\n",
        "    df.head(10)\n",
        "\n",
        "    df.replace(r'^\\?$', np.nan, regex=True, inplace=True)\n",
        "    df['authors'] = df['authors'].apply(lambda x: x if isinstance(x, list) else [])\n",
        "    df.fillna('', inplace=True)\n",
        "    df['topic'] = search_term\n",
        "    \n",
        "    return spark.createDataFrame(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nO-opUIWrwSS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topics = [\n",
        "    ['type', '1', 'diabetes'], \n",
        "    ['creutzfeldt', 'jakob', 'disease'], \n",
        "    ['post', 'traumatic', 'stress', 'disorder'],\n",
        "    ['heart', 'disease'],\n",
        "    ['AIDS'],\n",
        "    ['breast', 'cancer']\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiDY6GVLrzk8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "outputId": "dfa3a250-aecf-4f1a-e101-97f6c755712f"
      },
      "source": [
        "texts = None\n",
        "\n",
        "np.random.seed(123)\n",
        "for terms in topics:\n",
        "    num_docs = np.random.randint(200, 1000)\n",
        "    print('terms', terms, 'num_docs', num_docs)\n",
        "    if texts is None:\n",
        "        texts = query(terms, num_docs)\n",
        "    else:\n",
        "        texts = texts.union(query(terms, num_docs))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "terms ['type', '1', 'diabetes'] num_docs 710\n",
            "Searching PubMed abstracts for documents containing term:  type+1+diabetes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/Bio/Entrez/__init__.py:617: UserWarning: \n",
            "Email address is not specified.\n",
            "\n",
            "To make use of NCBI's E-utilities, NCBI requires you to specify your\n",
            "email address with each request.  As an example, if your email address\n",
            "is A.N.Other@example.com, you can specify it as follows:\n",
            "   from Bio import Entrez\n",
            "   Entrez.email = 'A.N.Other@example.com'\n",
            "In case of excessive usage of the E-utilities, NCBI will attempt to contact\n",
            "a user at the email address provided before blocking access to the\n",
            "E-utilities.\n",
            "  E-utilities.\"\"\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "terms ['creutzfeldt', 'jakob', 'disease'] num_docs 565\n",
            "Searching PubMed abstracts for documents containing term:  creutzfeldt+jakob+disease\n",
            "terms ['post', 'traumatic', 'stress', 'disorder'] num_docs 582\n",
            "Searching PubMed abstracts for documents containing term:  post+traumatic+stress+disorder\n",
            "terms ['heart', 'disease'] num_docs 522\n",
            "Searching PubMed abstracts for documents containing term:  heart+disease\n",
            "terms ['AIDS'] num_docs 298\n",
            "Searching PubMed abstracts for documents containing term:  AIDS\n",
            "terms ['breast', 'cancer'] num_docs 942\n",
            "Searching PubMed abstracts for documents containing term:  breast+cancer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkLkDZMfr3mH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "174e0902-5de5-45b9-c807-c29f38be15af"
      },
      "source": [
        "texts.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+---------------+\n",
            "|               title|             authors|              source|                text|          topic|\n",
            "+--------------------+--------------------+--------------------+--------------------+---------------+\n",
            "|Correction to: Da...|  [Paik J, Blair HA]|Drugs. 2019 Nov 2...|The article Dapag...|type+1+diabetes|\n",
            "|Insulin-Independe...|[Gunawardana SC, ...|Transplant Direct...|As our previous p...|type+1+diabetes|\n",
            "|Interleukin-6 and...|[Siewko K, Maciul...|Biomed Res Int. 2...|Aim: The aim of o...|type+1+diabetes|\n",
            "|The Effect of Com...|[Hendrijantini N,...|Contemp Clin Dent...|Background: Prolo...|type+1+diabetes|\n",
            "|Cytotoxic T-lymph...|[Alshareef SA, Om...|BMC Res Notes. 20...|OBJECTIVES: This ...|type+1+diabetes|\n",
            "|Do-It-Yourself (D...|            [Hng TM]|J Diabetes Sci Te...|Do-It-Yourself cl...|type+1+diabetes|\n",
            "|The Endocannabino...|[Argenziano M, To...|Int J Mol Sci. 20...|Endocannabinoid s...|type+1+diabetes|\n",
            "|In brief: A new g...|                  []|Med Lett Drugs Th...|                    |type+1+diabetes|\n",
            "|Special Considera...|[Barry-Menkhaus S...|J Pediatr Psychol...|OBJECTIVE: The Am...|type+1+diabetes|\n",
            "|IN SILICO TRIALS ...|[Toffanin C, Koza...|Diabetes Technol ...|Objective Safety ...|type+1+diabetes|\n",
            "|Exploring parenta...|[Boucher SE, Aum ...|Diabet Med. 2019 ...|AIMS: To explore ...|type+1+diabetes|\n",
            "|Glutamic Acid Dec...|[Zhu Y, Qian L, L...|Diabetes Metab J....|BACKGROUND: The d...|type+1+diabetes|\n",
            "|Diabetes mellitus...|[Bai J, Gao Q, Wa...|Aging Clin Exp Re...|BACKGROUND: Low-e...|type+1+diabetes|\n",
            "|The risk of progr...|[Jacobsen LM, Boc...|Diabetologia. 201...|AIMS/HYPOTHESIS: ...|type+1+diabetes|\n",
            "|Loss of ubiquitin...|[Wang F, Sun F, L...|Cell Death Dis. 2...|Type 1 diabetes (...|type+1+diabetes|\n",
            "|Autoimmune Diabet...|[Argente-Pla M, M...|Ann Transplant. 2...|BACKGROUND Pancre...|type+1+diabetes|\n",
            "|Testing an audit ...|[Shulman R, Zenle...|BMC Health Serv R...|BACKGROUND: When ...|type+1+diabetes|\n",
            "|Antithrombotic th...|[Rocca B, Rubboli...|Eur J Prev Cardio...|BACKGROUND: Diabe...|type+1+diabetes|\n",
            "|Association of co...|[Tummanapalli SS,...|Clin Neurophysiol...|OBJECTIVE: Cornea...|type+1+diabetes|\n",
            "|Personalized Nutr...|[Bashiardes S, Ab...|J Pediatr Gastroe...|The human genome ...|type+1+diabetes|\n",
            "+--------------------+--------------------+--------------------+--------------------+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ8Js9UD7Gij",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "dd0a4e8e-7ab8-498d-8638-25dd4e20927b"
      },
      "source": [
        "texts.first()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(title='Correction to: Dapagliflozin: A Review in Type 1 Diabetes.', authors=['Paik J', 'Blair HA'], source='Drugs. 2019 Nov 26. pii: 10.1007/s40265-019-01238-2. doi: 10.1007/s40265-019-01238-2.', text='The article Dapagliflozin: A Review in Type 1 Diabetes, written by Julia Paik and Hannah A. Blair, was originally published Online First without Open Access.', topic='type+1+diabetes')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcNbfV3sr7_O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "18cad655-0c4d-4dee-8389-3481236a1fe1"
      },
      "source": [
        "texts = texts.filter('text != \"\"').persist()\n",
        "texts.count()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3330"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpKDZusTr_K8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test = texts.randomSplit(weights=[0.8, 0.2], seed=123)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQSCRTSOsCpr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size=500"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVzfvJG2m60_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import pyspark\n",
        "#from pyspark.ml.feature import RegexTokenizer\n",
        "\n",
        "from sparknlp.annotator import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer()         \\\n",
        "    .setInputCols(\"sentence\")   \\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "# tokenizer = RegexTokenizer( inputCol=\"sentence\", outputCol=\"token\" )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6SBxUXysGpZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sparknlp.annotator import SentenceDetector\n",
        "\n",
        "sentence_detector = SentenceDetector( ) \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"sentence\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCDImS2Jmy_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sparknlp.base import DocumentAssembler\n",
        "\n",
        "document_assembler = DocumentAssembler().setInputCol(\"text\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdYA4PSBsM2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sparknlp.base import Finisher\n",
        "\n",
        "finisher = Finisher( )\n",
        "\n",
        "finisher = finisher.setInputCols('token')\n",
        "finisher = finisher.setOutputCols(['tokens'])\n",
        "finisher = finisher.setOutputAsArray(True)\n",
        "#finisher.setIncludeKeys(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0NX3vfH1Ng7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sw_remover = spark_ft.StopWordsRemover()\\\n",
        "    .setInputCol('tokens')\\\n",
        "    .setOutputCol('cleantokens')\\\n",
        "    .setStopWords(spark_ft.StopWordsRemover.loadDefaultStopWords('english'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl6afgyb2wLD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hashingtf = spark_ft.HashingTF()\\\n",
        "    .setInputCol('cleantokens')\\\n",
        "    .setOutputCol('tf')\\\n",
        "    .setNumFeatures(vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjihCFKF21c2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idf = spark_ft.IDF()\\\n",
        "    .setInputCol('tf')\\\n",
        "    .setOutputCol('tfidf')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRFfTb0P24dH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_indexer = spark_ft.StringIndexer(inputCol='topic', outputCol='label')\n",
        "\n",
        "#model = label_indexer.fit(texts)\n",
        "#df = model.transform(texts)\n",
        "#\n",
        "#df.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7Um44Si277R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, finisher, sw_remover, hashingtf,idf, label_indexer])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRm5qTrS2_X2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipeline_model = pipeline.fit(train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQXRUIdo3B8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tx_train = pipeline_model.transform(train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJLZIKGi-kHP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "outputId": "b89d7cf3-59e2-41fb-bc64-f2c3dd3f509c"
      },
      "source": [
        "tx_train.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+---------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
            "|               title|             authors|              source|                text|          topic|              tokens|         cleantokens|                  tf|               tfidf|label|\n",
            "+--------------------+--------------------+--------------------+--------------------+---------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
            "|\"Out of the box\" ...|[Paret M, Barash ...|Acta Diabetol. 20...|BACKGROUND: Use o...|type+1+diabetes|[BACKGROUND, :, U...|[BACKGROUND, :, U...|(500,[1,2,4,24,25...|(500,[1,2,4,24,25...|  1.0|\n",
            "|A mHealth Support...|[Ng AH, Crowe TC,...|Digit Health. 201...|Aims and Objectiv...|type+1+diabetes|[Aims, and, Objec...|[Aims, Objectives...|(500,[1,9,19,20,2...|(500,[1,9,19,20,2...|  1.0|\n",
            "|A model-based app...|[Jiang T, Lu Y, D...|Stat Med. 2019 No...|Semicontinuous da...|type+1+diabetes|[Semicontinuous, ...|[Semicontinuous, ...|(500,[1,9,14,15,1...|(500,[1,9,14,15,1...|  1.0|\n",
            "|A physician-initi...|[Reutens AT, Jand...|Contemp Clin Tria...|PURPOSE: Kidney d...|type+1+diabetes|[PURPOSE, :, Kidn...|[PURPOSE, :, Kidn...|(500,[1,6,8,13,17...|(500,[1,6,8,13,17...|  1.0|\n",
            "|A pilot study of ...|[Xian Y, Xu H, Ga...|Diabetes Metab Re...|BACKGROUND: The a...|type+1+diabetes|[BACKGROUND, :, T...|[BACKGROUND, :, a...|(500,[0,1,3,7,24,...|(500,[0,1,3,7,24,...|  1.0|\n",
            "|A retrospective m...|[Mulvaney SA, Mar...|Transl Behav Med....|Psychosocial guid...|type+1+diabetes|[Psychosocial, gu...|[Psychosocial, gu...|(500,[9,18,19,20,...|(500,[9,18,19,20,...|  1.0|\n",
            "|Activation of the...|[Nomoto H, Pei L,...|Diabetologia. 201...|AIMS/HYPOTHESIS: ...|type+1+diabetes|[AIMS/HYPOTHESIS,...|[AIMS/HYPOTHESIS,...|(500,[0,1,6,22,24...|(500,[0,1,6,22,24...|  1.0|\n",
            "|Adapting home tel...|[Raymond JK, Reid...|Contemp Clin Tria...|As more individua...|type+1+diabetes|[As, more, indivi...|[individuals, div...|(500,[1,16,20,22,...|(500,[1,16,20,22,...|  1.0|\n",
            "|Adult attachment ...|[Kelly CS, Berg C...|J Behav Med. 2019...|Anxious and avoid...|type+1+diabetes|[Anxious, and, av...|[Anxious, avoidan...|(500,[2,6,12,14,1...|(500,[2,6,12,14,1...|  1.0|\n",
            "|All trans-retinoi...|[Ramirez-Moreno A...|Fundam Clin Pharm...|All TransRetinoic...|type+1+diabetes|[All, TransRetino...|[TransRetinoic, A...|(500,[0,1,10,18,2...|(500,[0,1,10,18,2...|  1.0|\n",
            "|Amino Acid Polymo...|[Frommer L, Flesc...|J Clin Endocrinol...|CONTEXT: The stru...|type+1+diabetes|[CONTEXT, :, The,...|[CONTEXT, :, stru...|(500,[3,12,14,20,...|(500,[3,12,14,20,...|  1.0|\n",
            "|Analysis of Preva...|[Ostrovski I, Lov...|Can J Diabetes. 2...|OBJECTIVES: To be...|type+1+diabetes|[OBJECTIVES, :, T...|[OBJECTIVES, :, b...|(500,[1,12,16,24,...|(500,[1,12,16,24,...|  1.0|\n",
            "|Angelica polysacc...|[Zhao Y, Liu C, Z...|Biofactors. 2019 ...|Diabetes, is the ...|type+1+diabetes|[Diabetes, ,, is,...|[Diabetes, ,, eig...|(500,[0,44,56,58,...|(500,[0,44,56,58,...|  1.0|\n",
            "|Anti-Neuronal Ant...|[Dimitriadou MM, ...|Neurotherapeutics...|Our study objecti...|type+1+diabetes|[Our, study, obje...|[study, objective...|(500,[1,3,6,10,11...|(500,[1,3,6,10,11...|  1.0|\n",
            "|Anti-inflammatory...|[Alves MT, Chaves...|Mol Biol Rep. 201...|Type 1 diabetes m...|type+1+diabetes|[Type, 1, diabete...|[Type, 1, diabete...|(500,[3,10,18,20,...|(500,[3,10,18,20,...|  1.0|\n",
            "| Antidiabetic Agents|                  []|                    |Management and tr...|type+1+diabetes|[Management, and,...|[Management, trea...|(500,[2,3,9,15,16...|(500,[2,3,9,15,16...|  1.0|\n",
            "|Antithrombotic th...|[Rocca B, Rubboli...|Eur J Prev Cardio...|BACKGROUND: Diabe...|type+1+diabetes|[BACKGROUND, :, D...|[BACKGROUND, :, D...|(500,[2,17,18,20,...|(500,[2,17,18,20,...|  1.0|\n",
            "|Assessing Health-...|[Hilliard ME, Min...|J Pediatr Psychol...|OBJECTIVE: To dev...|type+1+diabetes|[OBJECTIVE, :, To...|[OBJECTIVE, :, de...|(500,[2,11,19,23,...|(500,[2,11,19,23,...|  1.0|\n",
            "|Association of co...|[Tummanapalli SS,...|Clin Neurophysiol...|OBJECTIVE: Cornea...|type+1+diabetes|[OBJECTIVE, :, Co...|[OBJECTIVE, :, Co...|(500,[1,2,23,24,2...|(500,[1,2,23,24,2...|  1.0|\n",
            "|Association of se...|[Jensen MH, Dethl...|Acta Diabetol. 20...|AIMS: Severe hypo...|type+1+diabetes|[AIMS, :, Severe,...|[AIMS, :, Severe,...|(500,[3,4,17,18,2...|(500,[3,4,17,18,2...|  1.0|\n",
            "+--------------------+--------------------+--------------------+--------------------+---------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9sdFUC9HK3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tx_test = pipeline_model.transform(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwdsfF8cCiLK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = tx_train.select('title', 'label', 'tfidf').toPandas()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohIbtxIdGjvp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "1df1a039-dff7-48b4-cb65-434b27138746"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>label</th>\n",
              "      <th>tfidf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"Out of the box\" solution for skin problems du...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>(0.0, 1.9988735601520602, 1.7457491635792217, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A mHealth Support Program for Australian Young...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>(0.0, 2.99831034022809, 0.0, 0.0, 0.0, 0.0, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A model-based approach for clustering of multi...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>(0.0, 1.9988735601520602, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A physician-initiated double-blind, randomised...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>(0.0, 0.9994367800760301, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A pilot study of preproinsulin peptides reacti...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>(2.7606661832067827, 4.997183900380151, 0.0, 1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  ...                                              tfidf\n",
              "0  \"Out of the box\" solution for skin problems du...  ...  (0.0, 1.9988735601520602, 1.7457491635792217, ...\n",
              "1  A mHealth Support Program for Australian Young...  ...  (0.0, 2.99831034022809, 0.0, 0.0, 0.0, 0.0, 0....\n",
              "2  A model-based approach for clustering of multi...  ...  (0.0, 1.9988735601520602, 0.0, 0.0, 0.0, 0.0, ...\n",
              "3  A physician-initiated double-blind, randomised...  ...  (0.0, 0.9994367800760301, 0.0, 0.0, 0.0, 0.0, ...\n",
              "4  A pilot study of preproinsulin peptides reacti...  ...  (2.7606661832067827, 4.997183900380151, 0.0, 1...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqN5hQKXGudH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "89d7b2cb-1e67-4eaf-e4d6-e0d329c19f0b"
      },
      "source": [
        "test_df = tx_test.select('title', 'label', 'tfidf').toPandas()\n",
        "test_df.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>label</th>\n",
              "      <th>tfidf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A Multiple Hypothesis Approach to Estimating M...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.5677194588668...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A Systematic Review of Case-Identification Alg...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>(0.0, 0.9994367800760301, 0.0, 1.5018377541827...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A composite immune signature parallels disease...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>(0.0, 0.9994367800760301, 3.4914983271584434, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A preclinical assessment to repurpose drugs to...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>(2.7606661832067827, 0.0, 5.237247490737666, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A review of the NG17 recommendations for the u...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.7031583766004...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  ...                                              tfidf\n",
              "0  A Multiple Hypothesis Approach to Estimating M...  ...  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.5677194588668...\n",
              "1  A Systematic Review of Case-Identification Alg...  ...  (0.0, 0.9994367800760301, 0.0, 1.5018377541827...\n",
              "2  A composite immune signature parallels disease...  ...  (0.0, 0.9994367800760301, 3.4914983271584434, ...\n",
              "3  A preclinical assessment to repurpose drugs to...  ...  (2.7606661832067827, 0.0, 5.237247490737666, 0...\n",
              "4  A review of the NG17 recommendations for the u...  ...  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.7031583766004...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtQt6FuLG-34",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_X = tf.convert_to_tensor(np.vstack(train_df['tfidf'].apply(lambda sv: sv.toArray()).tolist()), dtype=tf.float32)\n",
        "train_Y = tf.convert_to_tensor(pd.get_dummies(train_df['label']).values, dtype=tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0x1q7DEHUTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_X = tf.convert_to_tensor(np.vstack(test_df['tfidf'].apply(lambda sv: sv.toArray()).tolist()), dtype=tf.float32)\n",
        "test_Y = tf.convert_to_tensor(pd.get_dummies(test_df['label']).values, dtype=tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJM-fW8HHYjY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters\n",
        "learning_rate = 0.1\n",
        "num_steps = 300\n",
        "batch_size = 128\n",
        "display_step = 10\n",
        "\n",
        "# Network Parameters\n",
        "num_input = vocab_size\n",
        "n_hidden_1 = int(vocab_size / 3) # 1st layer number of neurons\n",
        "n_hidden_2 = int(vocab_size / 3) # 2nd layer number of neurons\n",
        "num_classes = len(topics)\n",
        "\n",
        "# tf Graph input\n",
        "X = tf.placeholder(\"float\", [None, num_input])\n",
        "Y = tf.placeholder(\"float\", [None, num_classes])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehMFKAgmHcWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Store layers weight & bias\n",
        "weights = {\n",
        "    'h1': tf.Variable(tf.random_normal([num_input, n_hidden_1])),\n",
        "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
        "    'out': tf.Variable(tf.random_normal([n_hidden_2, num_classes]))\n",
        "}\n",
        "biases = {\n",
        "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
        "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
        "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTpN1nqWHgSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create model\n",
        "def neural_net(x):\n",
        "    # Hidden fully connected layer with 256 neurons\n",
        "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
        "    # Hidden fully connected layer with 256 neurons\n",
        "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
        "    # Output fully connected layer with a neuron for each class\n",
        "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
        "    return out_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gx8bG57bHj_c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "69e62618-9de8-4850-ff79-d3bf2717f95a"
      },
      "source": [
        "# Construct model\n",
        "logits = neural_net(train_X)\n",
        "\n",
        "# Define loss and optimizer\n",
        "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
        "    logits=logits, labels=train_Y))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "\n",
        "# Evaluate model (with test logits, for dropout to be disabled)\n",
        "y_pred_op = tf.argmax(logits, 1)\n",
        "y_true_op = tf.argmax(train_Y, 1)\n",
        "correct_pred_op = tf.equal(y_pred_op, y_true_op)\n",
        "accuracy_op = tf.reduce_mean(tf.cast(correct_pred_op, tf.float32))\n",
        "\n",
        "# Initialize the variables (i.e. assign their default value)\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-35-7fbf9c4a70fb>:5: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEqwZNohHnX1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "bdcd04e5-253b-40af-ed8a-c3c8bf6ba8b4"
      },
      "source": [
        "# Start training\n",
        "with tf.Session() as sess:\n",
        "    # Run the initializer\n",
        "    sess.run(init)\n",
        "    tf.train.start_queue_runners(sess)\n",
        "    train_X_eval = train_X.eval()\n",
        "    train_Y_eval = train_Y.eval()\n",
        "    test_X_eval = test_X.eval()\n",
        "    test_Y_eval = test_Y.eval()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-36-69f18b32c202>:4: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8yGwmogHsni",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        },
        "outputId": "56e507a5-90ca-432b-e517-af76daba0e7c"
      },
      "source": [
        "# Start training\n",
        "with tf.Session() as sess:\n",
        "    # Run the initializer\n",
        "    sess.run(init)\n",
        "    tf.train.start_queue_runners(sess)\n",
        "    for step in range(1, num_steps+1):\n",
        "        x, y = resample(train_X_eval, train_Y_eval, n_samples=100)\n",
        "        # Run optimization op (backprop)\n",
        "        sess.run(train_op, feed_dict={X: x, Y: y})\n",
        "        if step % display_step == 0 or step == 1:\n",
        "            # Calculate batch loss and accuracy\n",
        "            loss, acc = sess.run([loss_op, accuracy_op], feed_dict={X: x, Y: y})\n",
        "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \"{:.3f}\".format(acc))\n",
        "\n",
        "    print(\"Optimization Finished!\")\n",
        "\n",
        "    accuracy, y_pred, y_true = sess.run([accuracy_op, y_pred_op, y_true_op], feed_dict={X: test_X.eval(), Y: test_Y.eval()})\n",
        "    print(\"Testing Accuracy:\", accuracy)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.\n",
            "Step 1, Minibatch Loss= 12936.9717, Training Accuracy= 0.393\n",
            "Step 10, Minibatch Loss= 2401.2583, Training Accuracy= 0.700\n",
            "Step 20, Minibatch Loss= 408.4059, Training Accuracy= 0.898\n",
            "Step 30, Minibatch Loss= 105.8308, Training Accuracy= 0.948\n",
            "Step 40, Minibatch Loss= 33.2053, Training Accuracy= 0.976\n",
            "Step 50, Minibatch Loss= 7.4082, Training Accuracy= 0.989\n",
            "Step 60, Minibatch Loss= 4.4690, Training Accuracy= 0.992\n",
            "Step 70, Minibatch Loss= 2.5371, Training Accuracy= 0.994\n",
            "Step 80, Minibatch Loss= 2.9678, Training Accuracy= 0.993\n",
            "Step 90, Minibatch Loss= 2.1925, Training Accuracy= 0.994\n",
            "Step 100, Minibatch Loss= 3.1888, Training Accuracy= 0.994\n",
            "Step 110, Minibatch Loss= 2.5573, Training Accuracy= 0.994\n",
            "Step 120, Minibatch Loss= 2.8129, Training Accuracy= 0.995\n",
            "Step 130, Minibatch Loss= 3.6936, Training Accuracy= 0.995\n",
            "Step 140, Minibatch Loss= 3.8285, Training Accuracy= 0.995\n",
            "Step 150, Minibatch Loss= 2.8254, Training Accuracy= 0.994\n",
            "Step 160, Minibatch Loss= 2.9666, Training Accuracy= 0.995\n",
            "Step 170, Minibatch Loss= 4.3126, Training Accuracy= 0.994\n",
            "Step 180, Minibatch Loss= 2.4147, Training Accuracy= 0.995\n",
            "Step 190, Minibatch Loss= 2.7643, Training Accuracy= 0.995\n",
            "Step 200, Minibatch Loss= 4.2095, Training Accuracy= 0.994\n",
            "Step 210, Minibatch Loss= 3.5597, Training Accuracy= 0.995\n",
            "Step 220, Minibatch Loss= 2.1774, Training Accuracy= 0.995\n",
            "Step 230, Minibatch Loss= 3.0013, Training Accuracy= 0.995\n",
            "Step 240, Minibatch Loss= 1.8889, Training Accuracy= 0.995\n",
            "Step 250, Minibatch Loss= 3.8901, Training Accuracy= 0.995\n",
            "Step 260, Minibatch Loss= 4.3432, Training Accuracy= 0.995\n",
            "Step 270, Minibatch Loss= 3.8827, Training Accuracy= 0.995\n",
            "Step 280, Minibatch Loss= 2.0551, Training Accuracy= 0.995\n",
            "Step 290, Minibatch Loss= 2.6975, Training Accuracy= 0.995\n",
            "Step 300, Minibatch Loss= 3.1944, Training Accuracy= 0.995\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.9951402\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iu4Fj6tHyR5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "outputId": "0e44315b-9102-4c60-a437-09b2686929ff"
      },
      "source": [
        "print(classification_report(y_true, y_pred, target_names=pipeline_model.stages[-1].labels))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                precision    recall  f1-score   support\n",
            "\n",
            "                 breast+cancer       0.99      1.00      0.99       719\n",
            "               type+1+diabetes       1.00      1.00      1.00       521\n",
            "post+traumatic+stress+disorder       1.00      1.00      1.00       430\n",
            "                 heart+disease       0.99      0.98      0.99       394\n",
            "     creutzfeldt+jakob+disease       1.00      1.00      1.00       388\n",
            "                          AIDS       0.99      0.99      0.99       223\n",
            "\n",
            "                      accuracy                           1.00      2675\n",
            "                     macro avg       1.00      0.99      0.99      2675\n",
            "                  weighted avg       1.00      1.00      1.00      2675\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhL1PEBMH5Ho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}